{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b657476e-1865-4687-898d-276c69eda4bc",
   "metadata": {},
   "source": [
    "# Converting the State Dict\n",
    "\n",
    "The training script (`train.py`) doesn't support any fancy saving/checkpointing methods, but it does optionally save the model right at the end of training into a safetensors file. In this notebook we'll show how to load in these saved weights for downstream evaluation and usage. This should hopefully become unneeded as frameworks integrate the changes needed to make FSDP+QLoRA work natively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a3fa90-3d40-45db-9e91-3489fc207a14",
   "metadata": {},
   "source": [
    "As an example, let's look at a model trained with the following command (using default settings for LoRA rank etc):\n",
    "\n",
    "`python train.py --save_model True --train_type qlora --output_dir qlora_output`\n",
    "\n",
    "We'll load the saved state_dict, and then copy the relevant weights into a PEFT model to save via their TODO method.\n",
    "\n",
    "Let's start by loading the state dict. If you uncomment the print statement, you'll see that for every linear layer that had a LoRA adapter, we have something like this:\n",
    "```\n",
    "base_model.model.model.layers.0.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([11272192, 1])\n",
    "base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight torch.bfloat16 torch.Size([8, 11008])\n",
    "base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight torch.bfloat16 torch.Size([4096, 8])\n",
    "```\n",
    "\n",
    "The base weights are flattened and quantized 4-bit values, which we won't need (we'll load the original base model later), and the lora_A and lora_B adapters are the ones we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4941f6c1-e232-4569-bce1-ee26f9326e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
      "Collecting peft\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.1.0+cu118)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.6)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate, peft\n",
      "Successfully installed accelerate-1.0.1 peft-0.13.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers bitsandbytes peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e88d60c-d066-4263-8e9e-d46e13f42ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting safetensors\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors\n",
      "Successfully installed safetensors-0.4.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4bb4b5-a250-489c-be56-5db542ac882e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello mommA\n",
      "base_model.model.lm_head.weight torch.bfloat16 torch.Size([128256, 8192])\n",
      "base_model.model.model.embed_tokens.weight torch.bfloat16 torch.Size([128256, 8192])\n",
      "base_model.model.model.layers.0.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.0.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.0.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.1.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.1.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.1.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.10.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.10.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.10.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.11.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.11.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.11.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.12.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.12.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.12.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.13.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.13.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.13.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.14.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.14.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.14.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.15.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.15.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.15.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.16.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.16.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.16.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.17.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.17.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.17.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.18.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.18.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.18.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.19.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.19.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.19.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.2.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.2.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.2.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.20.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.20.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.20.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.21.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.21.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.21.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.22.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.22.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.22.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.23.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.23.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.23.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.24.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.24.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.24.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.25.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.25.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.25.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.26.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.26.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.26.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.27.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.27.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.27.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.28.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.28.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.28.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.29.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.29.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.29.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.3.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.3.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.3.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.30.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.30.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.30.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.31.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.31.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.31.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.32.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.32.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.32.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.32.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.32.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.32.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.32.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.32.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.32.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.33.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.33.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.33.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.33.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.33.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.33.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.33.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.33.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.33.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.34.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.34.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.34.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.34.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.34.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.34.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.34.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.34.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.34.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.35.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.35.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.35.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.35.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.35.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.35.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.35.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.35.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.35.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.36.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.36.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.36.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.36.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.36.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.36.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.36.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.36.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.36.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.36.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.36.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.36.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.36.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.36.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.36.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.37.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.37.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.37.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.37.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.37.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.37.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.37.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.37.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.37.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.37.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.37.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.37.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.37.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.37.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.37.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.38.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.38.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.38.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.38.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.38.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.38.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.38.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.38.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.38.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.38.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.38.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.38.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.38.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.38.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.38.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.39.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.39.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.39.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.39.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.39.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.39.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.39.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.39.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.39.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.39.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.39.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.39.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.39.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.39.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.39.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.4.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.4.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.4.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.40.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.40.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.40.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.40.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.40.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.40.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.40.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.40.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.40.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.40.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.40.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.40.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.40.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.40.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.40.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.40.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.40.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.40.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.40.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.40.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.40.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.41.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.41.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.41.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.41.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.41.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.41.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.41.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.41.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.41.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.41.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.41.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.41.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.41.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.41.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.41.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.41.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.41.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.41.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.41.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.41.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.41.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.42.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.42.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.42.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.42.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.42.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.42.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.42.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.42.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.42.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.42.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.42.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.42.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.42.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.42.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.42.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.42.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.42.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.42.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.42.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.42.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.42.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.43.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.43.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.43.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.43.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.43.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.43.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.43.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.43.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.43.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.43.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.43.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.43.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.43.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.43.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.43.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.43.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.43.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.43.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.43.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.43.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.43.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.44.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.44.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.44.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.44.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.44.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.44.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.44.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.44.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.44.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.44.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.44.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.44.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.44.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.44.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.44.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.44.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.44.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.44.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.44.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.44.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.44.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.45.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.45.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.45.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.45.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.45.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.45.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.45.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.45.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.45.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.45.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.45.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.45.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.45.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.45.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.45.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.45.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.45.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.45.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.45.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.45.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.45.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.46.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.46.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.46.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.46.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.46.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.46.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.46.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.46.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.46.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.46.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.46.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.46.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.46.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.46.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.46.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.46.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.46.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.46.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.46.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.46.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.46.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.47.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.47.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.47.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.47.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.47.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.47.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.47.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.47.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.47.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.47.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.47.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.47.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.47.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.47.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.47.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.47.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.47.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.47.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.47.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.47.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.47.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.48.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.48.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.48.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.48.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.48.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.48.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.48.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.48.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.48.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.48.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.48.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.48.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.48.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.48.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.48.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.48.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.48.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.48.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.48.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.48.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.48.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.49.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.49.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.49.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.49.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.49.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.49.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.49.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.49.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.49.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.49.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.49.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.49.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.49.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.49.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.49.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.49.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.49.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.49.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.49.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.49.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.49.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.5.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.5.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.5.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.50.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.50.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.50.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.50.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.50.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.50.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.50.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.50.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.50.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.50.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.50.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.50.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.50.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.50.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.50.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.50.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.50.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.50.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.50.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.50.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.50.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.51.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.51.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.51.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.51.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.51.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.51.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.51.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.51.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.51.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.51.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.51.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.51.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.51.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.51.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.51.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.51.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.51.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.51.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.51.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.51.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.51.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.52.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.52.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.52.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.52.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.52.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.52.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.52.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.52.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.52.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.52.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.52.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.52.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.52.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.52.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.52.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.52.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.52.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.52.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.52.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.52.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.52.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.53.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.53.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.53.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.53.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.53.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.53.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.53.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.53.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.53.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.53.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.53.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.53.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.53.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.53.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.53.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.53.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.53.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.53.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.53.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.53.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.53.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.54.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.54.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.54.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.54.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.54.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.54.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.54.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.54.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.54.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.54.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.54.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.54.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.54.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.54.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.54.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.54.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.54.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.54.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.54.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.54.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.54.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.55.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.55.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.55.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.55.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.55.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.55.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.55.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.55.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.55.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.55.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.55.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.55.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.55.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.55.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.55.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.55.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.55.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.55.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.55.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.55.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.55.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.56.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.56.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.56.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.56.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.56.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.56.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.56.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.56.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.56.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.56.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.56.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.56.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.56.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.56.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.56.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.56.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.56.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.56.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.56.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.56.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.56.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.57.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.57.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.57.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.57.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.57.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.57.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.57.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.57.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.57.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.57.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.57.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.57.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.57.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.57.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.57.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.57.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.57.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.57.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.57.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.57.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.57.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.58.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.58.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.58.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.58.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.58.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.58.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.58.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.58.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.58.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.58.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.58.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.58.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.58.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.58.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.58.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.58.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.58.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.58.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.58.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.58.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.58.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.59.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.59.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.59.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.59.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.59.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.59.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.59.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.59.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.59.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.59.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.59.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.59.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.59.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.59.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.59.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.59.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.59.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.59.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.59.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.59.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.59.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.6.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.6.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.6.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.60.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.60.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.60.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.60.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.60.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.60.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.60.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.60.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.60.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.60.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.60.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.60.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.60.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.60.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.60.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.60.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.60.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.60.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.60.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.60.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.60.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.61.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.61.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.61.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.61.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.61.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.61.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.61.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.61.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.61.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.61.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.61.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.61.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.61.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.61.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.61.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.61.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.61.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.61.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.61.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.61.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.61.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.62.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.62.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.62.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.62.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.62.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.62.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.62.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.62.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.62.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.62.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.62.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.62.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.62.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.62.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.62.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.62.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.62.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.62.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.62.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.62.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.62.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.63.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.63.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.63.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.63.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.63.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.63.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.63.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.63.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.63.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.63.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.63.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.63.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.63.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.63.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.63.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.63.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.63.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.63.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.63.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.63.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.63.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.64.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.64.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.64.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.64.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.64.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.64.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.64.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.64.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.64.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.64.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.64.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.64.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.64.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.64.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.64.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.64.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.64.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.64.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.64.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.64.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.64.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.65.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.65.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.65.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.65.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.65.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.65.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.65.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.65.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.65.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.65.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.65.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.65.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.65.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.65.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.65.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.65.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.65.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.65.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.65.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.65.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.65.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.66.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.66.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.66.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.66.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.66.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.66.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.66.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.66.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.66.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.66.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.66.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.66.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.66.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.66.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.66.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.66.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.66.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.66.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.66.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.66.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.66.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.67.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.67.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.67.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.67.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.67.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.67.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.67.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.67.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.67.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.67.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.67.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.67.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.67.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.67.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.67.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.67.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.67.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.67.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.67.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.67.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.67.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.68.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.68.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.68.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.68.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.68.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.68.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.68.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.68.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.68.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.68.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.68.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.68.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.68.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.68.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.68.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.68.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.68.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.68.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.68.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.68.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.68.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.69.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.69.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.69.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.69.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.69.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.69.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.69.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.69.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.69.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.69.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.69.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.69.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.69.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.69.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.69.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.69.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.69.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.69.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.69.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.69.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.69.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.7.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.7.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.7.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.70.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.70.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.70.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.70.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.70.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.70.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.70.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.70.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.70.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.70.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.70.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.70.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.70.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.70.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.70.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.70.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.70.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.70.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.70.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.70.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.70.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.71.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.71.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.71.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.71.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.71.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.71.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.71.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.71.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.71.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.71.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.71.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.71.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.71.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.71.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.71.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.71.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.71.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.71.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.71.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.71.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.71.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.72.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.72.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.72.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.72.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.72.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.72.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.72.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.72.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.72.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.72.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.72.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.72.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.72.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.72.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.72.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.72.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.72.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.72.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.72.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.72.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.72.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.73.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.73.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.73.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.73.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.73.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.73.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.73.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.73.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.73.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.73.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.73.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.73.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.73.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.73.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.73.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.73.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.73.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.73.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.73.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.73.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.73.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.74.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.74.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.74.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.74.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.74.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.74.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.74.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.74.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.74.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.74.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.74.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.74.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.74.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.74.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.74.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.74.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.74.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.74.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.74.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.74.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.74.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.75.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.75.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.75.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.75.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.75.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.75.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.75.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.75.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.75.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.75.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.75.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.75.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.75.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.75.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.75.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.75.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.75.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.75.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.75.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.75.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.75.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.76.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.76.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.76.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.76.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.76.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.76.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.76.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.76.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.76.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.76.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.76.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.76.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.76.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.76.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.76.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.76.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.76.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.76.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.76.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.76.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.76.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.77.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.77.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.77.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.77.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.77.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.77.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.77.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.77.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.77.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.77.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.77.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.77.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.77.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.77.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.77.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.77.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.77.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.77.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.77.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.77.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.77.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.78.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.78.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.78.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.78.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.78.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.78.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.78.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.78.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.78.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.78.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.78.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.78.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.78.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.78.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.78.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.78.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.78.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.78.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.78.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.78.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.78.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.79.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.79.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.79.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.79.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.79.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.79.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.79.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.79.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.79.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.79.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.79.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.79.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.79.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.79.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.79.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.79.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.79.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.79.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.79.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.79.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.79.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.8.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.8.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.8.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.9.input_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.9.mlp.down_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight torch.float32 torch.Size([64, 28672])\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.9.mlp.up_proj.base_layer.weight torch.bfloat16 torch.Size([58720256, 1])\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight torch.float32 torch.Size([28672, 64])\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight torch.bfloat16 torch.Size([8192])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight torch.bfloat16 torch.Size([16777216, 1])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight torch.float32 torch.Size([8192, 64])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight torch.bfloat16 torch.Size([2097152, 1])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight torch.float32 torch.Size([64, 8192])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight torch.float32 torch.Size([1024, 64])\n",
      "base_model.model.model.norm.weight torch.bfloat16 torch.Size([8192])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "print(\"hello mommA\")\n",
    "tensors = {}\n",
    "with safe_open(\"./model_state_dict_tango.safetensors\", framework=\"pt\", device=0) as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k) # loads the full tensor given a key\n",
    "        print(k, tensors[k].dtype, tensors[k].shape) # Uncomment to view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a4876-c355-4b00-be1e-853de6be9ce1",
   "metadata": {},
   "source": [
    "To save memory, we can delete everything but the LoRA layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a63af21-1cbf-4c70-9841-63b1338ee757",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tensors:\n",
    "    if 'lora' not in k: tensors[k] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaa3483-cf79-44bf-9533-3937bd089f6e",
   "metadata": {},
   "source": [
    "Next, we load the base model and add a random adapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "856ed606-fd37-4249-a7c8-6bb33aa92adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.1.0+cu118)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00da1456-793f-451c-b5ce-03f05fb023af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (0.26.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "141e3f6d-c4a2-40f0-8887-68aacf5cbfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e0399d0-f471-47fc-8651-4c2107df1bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: accelerate 1.0.1\n",
      "Uninstalling accelerate-1.0.1:\n",
      "  Successfully uninstalled accelerate-1.0.1\n",
      "Found existing installation: transformers 4.46.0\n",
      "Uninstalling transformers-4.46.0:\n",
      "  Successfully uninstalled transformers-4.46.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mFiles removed: 573\n",
      "Collecting accelerate>=0.26.0\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers>=4.46.0\n",
      "  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (0.26.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.46.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.46.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.46.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.46.0) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate, transformers\n",
      "Successfully installed accelerate-1.0.1 transformers-4.46.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall accelerate transformers -y\n",
    "!pip cache purge\n",
    "!pip install -U \"accelerate>=0.26.0\" \"transformers>=4.46.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f83d8bc8-0bfe-440c-97e5-1cbc6a599741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as tf\n",
    "tf.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac681a6b-1265-45c2-b173-dc519202ed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/tango/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA H100 NVL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:  13%|█▎        | 4/30 [08:00<52:54, 122.09s/it]/workspace/tango/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:653: UserWarning: Not enough free disk space to download the file. The expected file size is: 4664.13 MB. The target location /root/.cache/huggingface/hub/models--nvidia--Llama-3.1-Nemotron-70B-Instruct-HF/blobs only has 2238.61 MB free disk space.\n",
      "  warnings.warn(\n",
      "Downloading shards:  13%|█▎        | 4/30 [08:53<57:46, 133.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: [Errno 28] No space left on device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1709/1837244538.py\", line 20, in <module>\n",
      "    model = LlamaForCausalLM.from_pretrained(\n",
      "  File \"/workspace/tango/venv/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3769, in from_pretrained\n",
      "    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n",
      "  File \"/workspace/tango/venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 1098, in get_checkpoint_shard_files\n",
      "    cached_filename = cached_file(\n",
      "  File \"/workspace/tango/venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 403, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "  File \"/workspace/tango/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/workspace/tango/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 862, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "  File \"/workspace/tango/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1011, in _hf_hub_download_to_cache_dir\n",
      "    _download_to_tmp_and_move(\n",
      "  File \"/workspace/tango/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1545, in _download_to_tmp_and_move\n",
      "    http_get(\n",
      "  File \"/workspace/tango/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 457, in http_get\n",
      "    temp_file.write(chunk)\n",
      "OSError: [Errno 28] No space left on device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, BitsAndBytesConfig\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Configure BitsAndBytes\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Load model\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\",\n",
    "        device_map=None,  # Add this line\n",
    "        low_cpu_mem_usage=False,\n",
    "        use_cache=False,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16  # Add this line\n",
    "    )\n",
    "    \n",
    "    # Freeze parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Configure LoRA\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM, \n",
    "        inference_mode=False, \n",
    "        r=64, \n",
    "        lora_alpha=16, \n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"k_proj\", \"q_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"]\n",
    "    )\n",
    "    \n",
    "    # Apply PEFT\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    \n",
    "    # Print first few state dict keys\n",
    "    print(list(model.state_dict().keys())[:10])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46f0c7b1-0c08-4c7e-8475-a1c293ce247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0+cu118\n",
      "Transformers version: 4.46.0\n",
      "Accelerate version: 1.0.1\n",
      "Bitsandbytes version: 0.44.1\n",
      "PEFT version: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import accelerate\n",
    "import bitsandbytes\n",
    "import peft\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"Accelerate version: {accelerate.__version__}\")\n",
    "print(f\"Bitsandbytes version: {bitsandbytes.__version__}\")\n",
    "print(f\"PEFT version: {peft.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879e24cd-eb72-4d23-8583-12cd91ed117f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9762b0b2d04f8db38f2072b512d81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b792208f8539415ab358f16054bd3e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/59.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b1de91df43463bb864999b1003a3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc1642a154e42ad90f1d9ad4e6b3b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00030.safetensors:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932908fc3fa4444ca5a9575e718f8030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac63fbca7d734cd08ba89ec531fb0be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6001933a5ed946848b26c1bcf05a36bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013b0c3b3753430ca2edcddde3c13eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cc2d376a334522a0a169299fbe2916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362f7774da084b96bc0d763548dccb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c926aa2667ac4614a4896ba641ce2c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e8c029866d409990c867b73ae672e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a941a57ee364302931e61ca01fcb254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5e5d4fff304b92a36007173d7a74d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d294d76e9e7407698fac1146792c4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ae0edc119741d6a4aaf89360208322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96cada53dfb42a995b0bbb45a9ed862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804eb35839404888aea1530b54c233ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6e59fa597649c5a7912be5fa9748a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b9d3f7573f4e35a0c7af6667eca510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25343e701ba4cb5aff14a91f43a5504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd051321ca144621aed435a37ff9af42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62faa920c334dd7bcbef7bf460b2808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00020-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d9f505336041fb921cbe856710d29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00021-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444aa109dcec40cf823ebc921e3e760c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00022-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03dd95c2d6a64aa08e931bb74954ee6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00023-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f100d8ae8c74655bdc16e4e4877f67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eada3be3c63144939a695bb54cc5da7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffc30fb652742a795e0f45e6af3713d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dead027a3024437388f5b09a6892e152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d567a57ef214bfeb24dad68337fd384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6f160b245644fd9d5937225d281c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89f9fe316cd4c0394d96d76f6a1c1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00030.safetensors:   0%|          | 0.00/2.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abfa22e07c94102808339639a4b6390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82ecb3901684208be7635d791954fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['base_model.model.model.embed_tokens.weight',\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight',\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.absmax',\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_map',\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4',\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight',\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight',\n",
       " 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight',\n",
       " 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.absmax',\n",
       " 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_map']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, BitsAndBytesConfig\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Make sure the compute type, target modules, rank, alpha etc match!\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\",\n",
    "    use_cache=False,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "# Freeze\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add LoRA (make sure your rank (r) and alpha (lora_alpha) values match those used in training!)\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False, r=64, lora_alpha=16, lora_dropout=0.1,\n",
    "    target_modules=[\"k_proj\", \"q_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Check out the first few keys in the state dict:\n",
    "list(model.state_dict().keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970628c8-715b-41ca-bfcf-c7b18633443b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 8192)\n",
       "        (layers): ModuleList(\n",
       "          (0-79): 80 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=8192, out_features=8192, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=28672, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=28672, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=28672, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=28672, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=28672, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=28672, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=8192, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322501e6-9170-4cb6-bd14-ed070045f028",
   "metadata": {},
   "source": [
    "Now, if all goes well, we can replace the randomly initialized LoRA layers with our trained ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a26eb-18d3-4e0e-b593-1bacd4987005",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sd = model.state_dict()\n",
    "for k in new_sd:\n",
    "    if 'lora' in k:\n",
    "        new_sd[k] = tensors[k]\n",
    "\n",
    "model.load_state_dict(new_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6d7c0b-0a48-4479-9479-0576a79b2a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of LoRA parameters in model: 960\n",
      "First few LoRA keys in model: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight']\n",
      "\n",
      "Number of LoRA parameters in loaded weights: 960\n",
      "First few LoRA keys in loaded weights: ['base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight']\n",
      "\n",
      "Verifying LoRA weights:\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight: mean=0.000000, std=0.006359\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000335\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight: mean=0.000007, std=0.006352\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000536\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight: mean=-0.000000, std=0.006393\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight: mean=0.000003, std=0.001605\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight: mean=-0.000005, std=0.006361\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000174\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight: mean=0.000001, std=0.006365\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000233\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003404\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000963\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight: mean=0.000005, std=0.006368\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight: mean=0.000001, std=0.000524\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight: mean=-0.000010, std=0.006362\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight: mean=0.000003, std=0.000966\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight: mean=-0.000003, std=0.006478\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.001188\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight: mean=-0.000006, std=0.006374\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000278\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight: mean=0.000003, std=0.006414\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000443\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003424\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000716\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight: mean=-0.000008, std=0.006356\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000177\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight: mean=0.000007, std=0.006355\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000225\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight: mean=0.000004, std=0.006408\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight: mean=-0.000002, std=0.001157\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight: mean=0.000002, std=0.006376\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000302\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight: mean=0.000007, std=0.006385\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000344\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003403\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000413\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight: mean=-0.000007, std=0.006351\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000179\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight: mean=-0.000009, std=0.006352\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight: mean=-0.000002, std=0.000283\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight: mean=-0.000003, std=0.006426\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight: mean=-0.000008, std=0.001296\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight: mean=-0.000002, std=0.006384\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000344\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight: mean=0.000006, std=0.006391\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000370\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight: mean=0.000000, std=0.003408\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight: mean=-0.000003, std=0.001123\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight: mean=-0.000013, std=0.006358\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000181\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight: mean=-0.000001, std=0.006359\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000228\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight: mean=0.000002, std=0.006401\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight: mean=0.000009, std=0.001149\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight: mean=0.000007, std=0.006374\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000327\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight: mean=0.000002, std=0.006396\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000353\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight: mean=-0.000000, std=0.003401\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000371\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight: mean=0.000004, std=0.006356\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000180\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight: mean=-0.000003, std=0.006361\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000267\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight: mean=-0.000009, std=0.006430\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.001305\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight: mean=-0.000009, std=0.006371\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000279\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight: mean=0.000001, std=0.006379\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000321\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight: mean=-0.000002, std=0.003402\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000425\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight: mean=-0.000002, std=0.006350\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000143\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight: mean=-0.000001, std=0.006358\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000190\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight: mean=-0.000003, std=0.006397\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.001118\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight: mean=-0.000007, std=0.006380\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000294\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight: mean=-0.000005, std=0.006390\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000360\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight: mean=0.000000, std=0.003401\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000361\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight: mean=-0.000007, std=0.006356\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000135\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight: mean=-0.000009, std=0.006353\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000202\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight: mean=-0.000004, std=0.006413\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight: mean=-0.000000, std=0.001245\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight: mean=0.000003, std=0.006371\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000282\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight: mean=0.000011, std=0.006384\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000337\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight: mean=0.000002, std=0.003404\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000448\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight: mean=-0.000001, std=0.006352\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000141\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight: mean=-0.000005, std=0.006352\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000185\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight: mean=0.000005, std=0.006390\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight: mean=-0.000001, std=0.001168\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight: mean=-0.000001, std=0.006369\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000269\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight: mean=0.000010, std=0.006383\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000331\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight: mean=-0.000001, std=0.003403\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000400\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight: mean=0.000021, std=0.006354\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000138\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight: mean=-0.000014, std=0.006346\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000204\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight: mean=-0.000009, std=0.006392\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight: mean=-0.000000, std=0.001194\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight: mean=0.000001, std=0.006377\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000265\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight: mean=-0.000009, std=0.006387\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000335\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight: mean=0.000002, std=0.003409\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000561\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: mean=-0.000019, std=0.006352\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000223\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight: mean=0.000011, std=0.006358\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000282\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: mean=0.000010, std=0.006399\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: mean=-0.000002, std=0.001230\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight: mean=-0.000001, std=0.006374\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000310\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight: mean=-0.000002, std=0.006406\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000401\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight: mean=0.000004, std=0.003409\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000529\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: mean=-0.000009, std=0.006362\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000142\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight: mean=-0.000006, std=0.006352\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000187\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: mean=0.000013, std=0.006389\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: mean=-0.000001, std=0.001188\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight: mean=0.000006, std=0.006402\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000415\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight: mean=-0.000018, std=0.006426\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000483\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight: mean=0.000002, std=0.003410\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000530\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: mean=-0.000016, std=0.006355\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000154\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight: mean=-0.000000, std=0.006354\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight: mean=-0.000002, std=0.000342\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: mean=-0.000008, std=0.006396\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.001238\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight: mean=-0.000006, std=0.006380\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000302\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight: mean=-0.000005, std=0.006386\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000356\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003408\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000484\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: mean=-0.000007, std=0.006352\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000263\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight: mean=-0.000005, std=0.006357\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000287\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: mean=0.000003, std=0.006388\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: mean=-0.000003, std=0.001206\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight: mean=0.000004, std=0.006374\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000268\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight: mean=0.000000, std=0.006382\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000308\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003411\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000514\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: mean=-0.000007, std=0.006353\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000214\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight: mean=-0.000011, std=0.006353\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000316\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: mean=0.000000, std=0.006393\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.001232\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight: mean=0.000003, std=0.006382\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000316\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight: mean=0.000009, std=0.006406\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000403\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight: mean=-0.000001, std=0.003415\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000593\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: mean=0.000011, std=0.006356\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000214\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight: mean=0.000002, std=0.006354\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000270\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: mean=-0.000002, std=0.006408\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: mean=-0.000013, std=0.001271\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight: mean=-0.000001, std=0.006387\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000366\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight: mean=-0.000017, std=0.006436\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000486\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight: mean=-0.000000, std=0.003423\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000660\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: mean=-0.000007, std=0.006357\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000240\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight: mean=-0.000004, std=0.006352\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000289\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: mean=-0.000001, std=0.006388\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: mean=0.000002, std=0.001219\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight: mean=-0.000002, std=0.006404\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000391\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight: mean=0.000017, std=0.006446\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000509\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003417\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000618\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: mean=-0.000002, std=0.006358\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000346\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight: mean=0.000021, std=0.006362\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight: mean=-0.000002, std=0.000402\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: mean=0.000009, std=0.006404\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.001195\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight: mean=-0.000007, std=0.006416\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight: mean=0.000002, std=0.000464\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight: mean=-0.000003, std=0.006468\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000586\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight: mean=-0.000004, std=0.003422\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000664\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: mean=0.000010, std=0.006353\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000308\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight: mean=0.000003, std=0.006356\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000385\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: mean=-0.000003, std=0.006403\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: mean=-0.000004, std=0.001194\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight: mean=-0.000007, std=0.006444\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000532\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight: mean=0.000006, std=0.006529\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000690\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight: mean=-0.000000, std=0.003434\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000863\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: mean=0.000011, std=0.006360\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000303\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight: mean=0.000000, std=0.006356\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000385\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: mean=0.000000, std=0.006406\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: mean=0.000004, std=0.001209\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight: mean=-0.000004, std=0.006443\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000505\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight: mean=0.000007, std=0.006598\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000744\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight: mean=0.000007, std=0.003460\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000863\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: mean=0.000014, std=0.006360\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000266\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight: mean=0.000010, std=0.006361\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000298\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: mean=0.000009, std=0.006383\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: mean=-0.000003, std=0.001108\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight: mean=0.000003, std=0.006452\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000534\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight: mean=0.000016, std=0.006543\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight: mean=0.000001, std=0.000678\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight: mean=-0.000000, std=0.003437\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight: mean=-0.000002, std=0.000768\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: mean=-0.000003, std=0.006354\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000283\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight: mean=-0.000015, std=0.006351\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000293\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: mean=-0.000007, std=0.006387\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: mean=0.000000, std=0.001112\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight: mean=0.000001, std=0.006449\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000555\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight: mean=0.000001, std=0.006549\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000692\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight: mean=0.000005, std=0.003445\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000801\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: mean=0.000000, std=0.006361\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000243\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight: mean=-0.000004, std=0.006356\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000277\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: mean=0.000009, std=0.006388\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.001096\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight: mean=-0.000023, std=0.006445\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000532\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight: mean=-0.000010, std=0.006561\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight: mean=0.000001, std=0.000711\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight: mean=0.000001, std=0.003446\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000796\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: mean=0.000018, std=0.006354\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000293\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight: mean=0.000002, std=0.006353\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000301\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: mean=0.000007, std=0.006380\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: mean=-0.000002, std=0.001124\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight: mean=-0.000002, std=0.006472\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000571\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight: mean=0.000003, std=0.006568\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight: mean=0.000001, std=0.000704\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight: mean=-0.000002, std=0.003440\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000803\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: mean=0.000007, std=0.006358\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000293\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight: mean=-0.000006, std=0.006353\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight: mean=0.000002, std=0.000395\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: mean=0.000009, std=0.006386\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.001178\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight: mean=0.000020, std=0.006463\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000574\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight: mean=-0.000007, std=0.006542\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000687\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight: mean=-0.000001, std=0.003434\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000904\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: mean=-0.000001, std=0.006355\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000238\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight: mean=0.000003, std=0.006355\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000253\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: mean=-0.000016, std=0.006381\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.001061\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight: mean=0.000012, std=0.006462\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight: mean=-0.000003, std=0.000565\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight: mean=-0.000003, std=0.006555\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000702\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight: mean=0.000005, std=0.003431\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000754\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: mean=-0.000005, std=0.006359\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000296\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight: mean=0.000001, std=0.006352\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000373\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: mean=0.000000, std=0.006389\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: mean=-0.000009, std=0.001144\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight: mean=-0.000001, std=0.006495\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000624\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight: mean=0.000010, std=0.006603\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000744\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight: mean=-0.000004, std=0.003437\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000762\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: mean=0.000010, std=0.006356\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000358\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight: mean=-0.000000, std=0.006357\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000372\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: mean=0.000007, std=0.006405\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: mean=0.000000, std=0.001164\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight: mean=-0.000003, std=0.006516\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000630\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight: mean=-0.000013, std=0.006636\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000764\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight: mean=-0.000001, std=0.003444\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight: mean=0.000002, std=0.000798\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: mean=-0.000001, std=0.006369\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000348\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight: mean=0.000019, std=0.006354\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000353\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: mean=-0.000010, std=0.006395\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: mean=-0.000006, std=0.001137\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight: mean=-0.000009, std=0.006498\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000607\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight: mean=0.000002, std=0.006617\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight: mean=0.000001, std=0.000746\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight: mean=0.000002, std=0.003449\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000815\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: mean=0.000006, std=0.006371\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000415\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight: mean=-0.000006, std=0.006352\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000385\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: mean=0.000016, std=0.006398\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: mean=0.000005, std=0.001213\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight: mean=-0.000005, std=0.006491\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000598\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight: mean=0.000006, std=0.006643\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000771\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight: mean=-0.000004, std=0.003449\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000827\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: mean=0.000004, std=0.006362\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000357\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight: mean=0.000007, std=0.006357\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000337\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: mean=-0.000003, std=0.006398\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: mean=-0.000003, std=0.001177\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight: mean=0.000007, std=0.006541\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000663\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight: mean=0.000011, std=0.006723\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000830\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003434\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000735\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: mean=-0.000016, std=0.006371\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: mean=0.000001, std=0.000479\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight: mean=0.000017, std=0.006357\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000449\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: mean=0.000007, std=0.006409\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: mean=-0.000001, std=0.001223\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight: mean=0.000004, std=0.006505\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000611\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight: mean=-0.000019, std=0.006667\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000774\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight: mean=-0.000000, std=0.003441\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000779\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight: mean=-0.000009, std=0.006359\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000322\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight: mean=-0.000002, std=0.006350\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000348\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight: mean=-0.000016, std=0.006387\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight: mean=0.000000, std=0.001177\n",
      "base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight: mean=-0.000019, std=0.006524\n",
      "base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000633\n",
      "base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight: mean=0.000021, std=0.006670\n",
      "base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight: mean=-0.000002, std=0.000781\n",
      "base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003430\n",
      "base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000706\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight: mean=-0.000005, std=0.006368\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000447\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight: mean=-0.000007, std=0.006358\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000440\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight: mean=-0.000003, std=0.006425\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight: mean=0.000006, std=0.001243\n",
      "base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight: mean=0.000005, std=0.006515\n",
      "base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000615\n",
      "base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight: mean=0.000021, std=0.006696\n",
      "base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000794\n",
      "base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight: mean=-0.000005, std=0.003429\n",
      "base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000693\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight: mean=0.000004, std=0.006369\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000426\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight: mean=0.000012, std=0.006352\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000506\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight: mean=-0.000003, std=0.006415\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight: mean=0.000003, std=0.001185\n",
      "base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight: mean=0.000014, std=0.006461\n",
      "base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000535\n",
      "base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight: mean=-0.000003, std=0.006666\n",
      "base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000773\n",
      "base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight: mean=0.000000, std=0.003446\n",
      "base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000793\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight: mean=-0.000003, std=0.006372\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000403\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight: mean=0.000007, std=0.006351\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000412\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight: mean=0.000002, std=0.006403\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight: mean=0.000000, std=0.001194\n",
      "base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight: mean=-0.000008, std=0.006434\n",
      "base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000500\n",
      "base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight: mean=0.000001, std=0.006580\n",
      "base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000699\n",
      "base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight: mean=-0.000002, std=0.003434\n",
      "base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000720\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight: mean=-0.000002, std=0.006375\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000402\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight: mean=-0.000006, std=0.006356\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight: mean=0.000005, std=0.000433\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight: mean=0.000009, std=0.006397\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight: mean=-0.000000, std=0.001189\n",
      "base_model.model.model.layers.36.mlp.gate_proj.lora_A.default.weight: mean=0.000013, std=0.006437\n",
      "base_model.model.model.layers.36.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000501\n",
      "base_model.model.model.layers.36.mlp.up_proj.lora_A.default.weight: mean=0.000005, std=0.006528\n",
      "base_model.model.model.layers.36.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000638\n",
      "base_model.model.model.layers.36.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003435\n",
      "base_model.model.model.layers.36.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000749\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight: mean=-0.000015, std=0.006361\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000343\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight: mean=-0.000004, std=0.006356\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight: mean=-0.000002, std=0.000344\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight: mean=-0.000007, std=0.006417\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight: mean=0.000003, std=0.001204\n",
      "base_model.model.model.layers.37.mlp.gate_proj.lora_A.default.weight: mean=0.000001, std=0.006442\n",
      "base_model.model.model.layers.37.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000501\n",
      "base_model.model.model.layers.37.mlp.up_proj.lora_A.default.weight: mean=-0.000008, std=0.006542\n",
      "base_model.model.model.layers.37.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000647\n",
      "base_model.model.model.layers.37.mlp.down_proj.lora_A.default.weight: mean=-0.000000, std=0.003425\n",
      "base_model.model.model.layers.37.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000677\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight: mean=0.000006, std=0.006366\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000346\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight: mean=-0.000004, std=0.006354\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000315\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight: mean=0.000000, std=0.006389\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight: mean=-0.000003, std=0.001155\n",
      "base_model.model.model.layers.38.mlp.gate_proj.lora_A.default.weight: mean=-0.000003, std=0.006428\n",
      "base_model.model.model.layers.38.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000477\n",
      "base_model.model.model.layers.38.mlp.up_proj.lora_A.default.weight: mean=0.000011, std=0.006546\n",
      "base_model.model.model.layers.38.mlp.up_proj.lora_B.default.weight: mean=-0.000001, std=0.000661\n",
      "base_model.model.model.layers.38.mlp.down_proj.lora_A.default.weight: mean=0.000001, std=0.003423\n",
      "base_model.model.model.layers.38.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000673\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight: mean=0.000000, std=0.006358\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000257\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight: mean=0.000011, std=0.006352\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000254\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight: mean=-0.000009, std=0.006386\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight: mean=0.000008, std=0.001134\n",
      "base_model.model.model.layers.39.mlp.gate_proj.lora_A.default.weight: mean=-0.000005, std=0.006421\n",
      "base_model.model.model.layers.39.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000470\n",
      "base_model.model.model.layers.39.mlp.up_proj.lora_A.default.weight: mean=-0.000019, std=0.006503\n",
      "base_model.model.model.layers.39.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000612\n",
      "base_model.model.model.layers.39.mlp.down_proj.lora_A.default.weight: mean=-0.000005, std=0.003418\n",
      "base_model.model.model.layers.39.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000629\n",
      "base_model.model.model.layers.40.self_attn.q_proj.lora_A.default.weight: mean=0.000002, std=0.006359\n",
      "base_model.model.model.layers.40.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000241\n",
      "base_model.model.model.layers.40.self_attn.k_proj.lora_A.default.weight: mean=0.000007, std=0.006355\n",
      "base_model.model.model.layers.40.self_attn.k_proj.lora_B.default.weight: mean=0.000003, std=0.000275\n",
      "base_model.model.model.layers.40.self_attn.v_proj.lora_A.default.weight: mean=0.000001, std=0.006382\n",
      "base_model.model.model.layers.40.self_attn.v_proj.lora_B.default.weight: mean=-0.000000, std=0.001164\n",
      "base_model.model.model.layers.40.mlp.gate_proj.lora_A.default.weight: mean=-0.000003, std=0.006433\n",
      "base_model.model.model.layers.40.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000476\n",
      "base_model.model.model.layers.40.mlp.up_proj.lora_A.default.weight: mean=0.000016, std=0.006482\n",
      "base_model.model.model.layers.40.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000572\n",
      "base_model.model.model.layers.40.mlp.down_proj.lora_A.default.weight: mean=0.000002, std=0.003421\n",
      "base_model.model.model.layers.40.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000647\n",
      "base_model.model.model.layers.41.self_attn.q_proj.lora_A.default.weight: mean=0.000005, std=0.006359\n",
      "base_model.model.model.layers.41.self_attn.q_proj.lora_B.default.weight: mean=0.000001, std=0.000232\n",
      "base_model.model.model.layers.41.self_attn.k_proj.lora_A.default.weight: mean=0.000003, std=0.006354\n",
      "base_model.model.model.layers.41.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000295\n",
      "base_model.model.model.layers.41.self_attn.v_proj.lora_A.default.weight: mean=0.000006, std=0.006375\n",
      "base_model.model.model.layers.41.self_attn.v_proj.lora_B.default.weight: mean=-0.000002, std=0.001077\n",
      "base_model.model.model.layers.41.mlp.gate_proj.lora_A.default.weight: mean=0.000003, std=0.006423\n",
      "base_model.model.model.layers.41.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000467\n",
      "base_model.model.model.layers.41.mlp.up_proj.lora_A.default.weight: mean=0.000018, std=0.006473\n",
      "base_model.model.model.layers.41.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000567\n",
      "base_model.model.model.layers.41.mlp.down_proj.lora_A.default.weight: mean=0.000000, std=0.003414\n",
      "base_model.model.model.layers.41.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000592\n",
      "base_model.model.model.layers.42.self_attn.q_proj.lora_A.default.weight: mean=0.000007, std=0.006357\n",
      "base_model.model.model.layers.42.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000150\n",
      "base_model.model.model.layers.42.self_attn.k_proj.lora_A.default.weight: mean=0.000010, std=0.006351\n",
      "base_model.model.model.layers.42.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000172\n",
      "base_model.model.model.layers.42.self_attn.v_proj.lora_A.default.weight: mean=-0.000002, std=0.006375\n",
      "base_model.model.model.layers.42.self_attn.v_proj.lora_B.default.weight: mean=0.000003, std=0.001047\n",
      "base_model.model.model.layers.42.mlp.gate_proj.lora_A.default.weight: mean=0.000008, std=0.006421\n",
      "base_model.model.model.layers.42.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000460\n",
      "base_model.model.model.layers.42.mlp.up_proj.lora_A.default.weight: mean=-0.000005, std=0.006470\n",
      "base_model.model.model.layers.42.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000569\n",
      "base_model.model.model.layers.42.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003414\n",
      "base_model.model.model.layers.42.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000559\n",
      "base_model.model.model.layers.43.self_attn.q_proj.lora_A.default.weight: mean=-0.000007, std=0.006357\n",
      "base_model.model.model.layers.43.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000203\n",
      "base_model.model.model.layers.43.self_attn.k_proj.lora_A.default.weight: mean=-0.000008, std=0.006353\n",
      "base_model.model.model.layers.43.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000228\n",
      "base_model.model.model.layers.43.self_attn.v_proj.lora_A.default.weight: mean=0.000001, std=0.006379\n",
      "base_model.model.model.layers.43.self_attn.v_proj.lora_B.default.weight: mean=-0.000004, std=0.001093\n",
      "base_model.model.model.layers.43.mlp.gate_proj.lora_A.default.weight: mean=0.000012, std=0.006432\n",
      "base_model.model.model.layers.43.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000476\n",
      "base_model.model.model.layers.43.mlp.up_proj.lora_A.default.weight: mean=0.000013, std=0.006477\n",
      "base_model.model.model.layers.43.mlp.up_proj.lora_B.default.weight: mean=-0.000001, std=0.000573\n",
      "base_model.model.model.layers.43.mlp.down_proj.lora_A.default.weight: mean=0.000001, std=0.003412\n",
      "base_model.model.model.layers.43.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000581\n",
      "base_model.model.model.layers.44.self_attn.q_proj.lora_A.default.weight: mean=0.000001, std=0.006356\n",
      "base_model.model.model.layers.44.self_attn.q_proj.lora_B.default.weight: mean=0.000001, std=0.000234\n",
      "base_model.model.model.layers.44.self_attn.k_proj.lora_A.default.weight: mean=0.000010, std=0.006360\n",
      "base_model.model.model.layers.44.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000269\n",
      "base_model.model.model.layers.44.self_attn.v_proj.lora_A.default.weight: mean=0.000001, std=0.006389\n",
      "base_model.model.model.layers.44.self_attn.v_proj.lora_B.default.weight: mean=-0.000002, std=0.001199\n",
      "base_model.model.model.layers.44.mlp.gate_proj.lora_A.default.weight: mean=0.000007, std=0.006421\n",
      "base_model.model.model.layers.44.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000464\n",
      "base_model.model.model.layers.44.mlp.up_proj.lora_A.default.weight: mean=-0.000001, std=0.006461\n",
      "base_model.model.model.layers.44.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000547\n",
      "base_model.model.model.layers.44.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003416\n",
      "base_model.model.model.layers.44.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000591\n",
      "base_model.model.model.layers.45.self_attn.q_proj.lora_A.default.weight: mean=0.000007, std=0.006356\n",
      "base_model.model.model.layers.45.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000192\n",
      "base_model.model.model.layers.45.self_attn.k_proj.lora_A.default.weight: mean=-0.000012, std=0.006355\n",
      "base_model.model.model.layers.45.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000242\n",
      "base_model.model.model.layers.45.self_attn.v_proj.lora_A.default.weight: mean=0.000008, std=0.006380\n",
      "base_model.model.model.layers.45.self_attn.v_proj.lora_B.default.weight: mean=-0.000001, std=0.001119\n",
      "base_model.model.model.layers.45.mlp.gate_proj.lora_A.default.weight: mean=0.000005, std=0.006424\n",
      "base_model.model.model.layers.45.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000466\n",
      "base_model.model.model.layers.45.mlp.up_proj.lora_A.default.weight: mean=0.000021, std=0.006462\n",
      "base_model.model.model.layers.45.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000550\n",
      "base_model.model.model.layers.45.mlp.down_proj.lora_A.default.weight: mean=0.000002, std=0.003414\n",
      "base_model.model.model.layers.45.mlp.down_proj.lora_B.default.weight: mean=0.000002, std=0.000589\n",
      "base_model.model.model.layers.46.self_attn.q_proj.lora_A.default.weight: mean=-0.000006, std=0.006358\n",
      "base_model.model.model.layers.46.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000087\n",
      "base_model.model.model.layers.46.self_attn.k_proj.lora_A.default.weight: mean=-0.000004, std=0.006348\n",
      "base_model.model.model.layers.46.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000094\n",
      "base_model.model.model.layers.46.self_attn.v_proj.lora_A.default.weight: mean=-0.000001, std=0.006376\n",
      "base_model.model.model.layers.46.self_attn.v_proj.lora_B.default.weight: mean=-0.000004, std=0.001063\n",
      "base_model.model.model.layers.46.mlp.gate_proj.lora_A.default.weight: mean=0.000001, std=0.006415\n",
      "base_model.model.model.layers.46.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000452\n",
      "base_model.model.model.layers.46.mlp.up_proj.lora_A.default.weight: mean=0.000008, std=0.006451\n",
      "base_model.model.model.layers.46.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000526\n",
      "base_model.model.model.layers.46.mlp.down_proj.lora_A.default.weight: mean=-0.000002, std=0.003414\n",
      "base_model.model.model.layers.46.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000564\n",
      "base_model.model.model.layers.47.self_attn.q_proj.lora_A.default.weight: mean=0.000000, std=0.006354\n",
      "base_model.model.model.layers.47.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000130\n",
      "base_model.model.model.layers.47.self_attn.k_proj.lora_A.default.weight: mean=-0.000007, std=0.006352\n",
      "base_model.model.model.layers.47.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000141\n",
      "base_model.model.model.layers.47.self_attn.v_proj.lora_A.default.weight: mean=0.000005, std=0.006376\n",
      "base_model.model.model.layers.47.self_attn.v_proj.lora_B.default.weight: mean=-0.000008, std=0.001062\n",
      "base_model.model.model.layers.47.mlp.gate_proj.lora_A.default.weight: mean=-0.000002, std=0.006415\n",
      "base_model.model.model.layers.47.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000455\n",
      "base_model.model.model.layers.47.mlp.up_proj.lora_A.default.weight: mean=-0.000003, std=0.006444\n",
      "base_model.model.model.layers.47.mlp.up_proj.lora_B.default.weight: mean=0.000001, std=0.000520\n",
      "base_model.model.model.layers.47.mlp.down_proj.lora_A.default.weight: mean=0.000001, std=0.003412\n",
      "base_model.model.model.layers.47.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000566\n",
      "base_model.model.model.layers.48.self_attn.q_proj.lora_A.default.weight: mean=-0.000001, std=0.006354\n",
      "base_model.model.model.layers.48.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000125\n",
      "base_model.model.model.layers.48.self_attn.k_proj.lora_A.default.weight: mean=0.000000, std=0.006350\n",
      "base_model.model.model.layers.48.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000141\n",
      "base_model.model.model.layers.48.self_attn.v_proj.lora_A.default.weight: mean=0.000005, std=0.006364\n",
      "base_model.model.model.layers.48.self_attn.v_proj.lora_B.default.weight: mean=0.000000, std=0.001054\n",
      "base_model.model.model.layers.48.mlp.gate_proj.lora_A.default.weight: mean=-0.000002, std=0.006418\n",
      "base_model.model.model.layers.48.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000455\n",
      "base_model.model.model.layers.48.mlp.up_proj.lora_A.default.weight: mean=-0.000004, std=0.006456\n",
      "base_model.model.model.layers.48.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000546\n",
      "base_model.model.model.layers.48.mlp.down_proj.lora_A.default.weight: mean=0.000004, std=0.003412\n",
      "base_model.model.model.layers.48.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000548\n",
      "base_model.model.model.layers.49.self_attn.q_proj.lora_A.default.weight: mean=-0.000000, std=0.006355\n",
      "base_model.model.model.layers.49.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000184\n",
      "base_model.model.model.layers.49.self_attn.k_proj.lora_A.default.weight: mean=0.000014, std=0.006351\n",
      "base_model.model.model.layers.49.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000200\n",
      "base_model.model.model.layers.49.self_attn.v_proj.lora_A.default.weight: mean=0.000001, std=0.006367\n",
      "base_model.model.model.layers.49.self_attn.v_proj.lora_B.default.weight: mean=-0.000002, std=0.001028\n",
      "base_model.model.model.layers.49.mlp.gate_proj.lora_A.default.weight: mean=-0.000001, std=0.006411\n",
      "base_model.model.model.layers.49.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000442\n",
      "base_model.model.model.layers.49.mlp.up_proj.lora_A.default.weight: mean=0.000002, std=0.006448\n",
      "base_model.model.model.layers.49.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000525\n",
      "base_model.model.model.layers.49.mlp.down_proj.lora_A.default.weight: mean=-0.000001, std=0.003413\n",
      "base_model.model.model.layers.49.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000565\n",
      "base_model.model.model.layers.50.self_attn.q_proj.lora_A.default.weight: mean=0.000001, std=0.006356\n",
      "base_model.model.model.layers.50.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000092\n",
      "base_model.model.model.layers.50.self_attn.k_proj.lora_A.default.weight: mean=0.000006, std=0.006349\n",
      "base_model.model.model.layers.50.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000098\n",
      "base_model.model.model.layers.50.self_attn.v_proj.lora_A.default.weight: mean=-0.000014, std=0.006372\n",
      "base_model.model.model.layers.50.self_attn.v_proj.lora_B.default.weight: mean=0.000004, std=0.000987\n",
      "base_model.model.model.layers.50.mlp.gate_proj.lora_A.default.weight: mean=0.000006, std=0.006416\n",
      "base_model.model.model.layers.50.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000443\n",
      "base_model.model.model.layers.50.mlp.up_proj.lora_A.default.weight: mean=-0.000007, std=0.006450\n",
      "base_model.model.model.layers.50.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000530\n",
      "base_model.model.model.layers.50.mlp.down_proj.lora_A.default.weight: mean=0.000001, std=0.003412\n",
      "base_model.model.model.layers.50.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000531\n",
      "base_model.model.model.layers.51.self_attn.q_proj.lora_A.default.weight: mean=0.000002, std=0.006355\n",
      "base_model.model.model.layers.51.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000109\n",
      "base_model.model.model.layers.51.self_attn.k_proj.lora_A.default.weight: mean=0.000007, std=0.006355\n",
      "base_model.model.model.layers.51.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000134\n",
      "base_model.model.model.layers.51.self_attn.v_proj.lora_A.default.weight: mean=0.000015, std=0.006378\n",
      "base_model.model.model.layers.51.self_attn.v_proj.lora_B.default.weight: mean=0.000005, std=0.001060\n",
      "base_model.model.model.layers.51.mlp.gate_proj.lora_A.default.weight: mean=0.000005, std=0.006414\n",
      "base_model.model.model.layers.51.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000439\n",
      "base_model.model.model.layers.51.mlp.up_proj.lora_A.default.weight: mean=0.000001, std=0.006438\n",
      "base_model.model.model.layers.51.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000507\n",
      "base_model.model.model.layers.51.mlp.down_proj.lora_A.default.weight: mean=-0.000002, std=0.003412\n",
      "base_model.model.model.layers.51.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000539\n",
      "base_model.model.model.layers.52.self_attn.q_proj.lora_A.default.weight: mean=-0.000009, std=0.006349\n",
      "base_model.model.model.layers.52.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000174\n",
      "base_model.model.model.layers.52.self_attn.k_proj.lora_A.default.weight: mean=-0.000016, std=0.006355\n",
      "base_model.model.model.layers.52.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000236\n",
      "base_model.model.model.layers.52.self_attn.v_proj.lora_A.default.weight: mean=0.000010, std=0.006377\n",
      "base_model.model.model.layers.52.self_attn.v_proj.lora_B.default.weight: mean=0.000002, std=0.001082\n",
      "base_model.model.model.layers.52.mlp.gate_proj.lora_A.default.weight: mean=0.000008, std=0.006419\n",
      "base_model.model.model.layers.52.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000445\n",
      "base_model.model.model.layers.52.mlp.up_proj.lora_A.default.weight: mean=0.000007, std=0.006453\n",
      "base_model.model.model.layers.52.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000525\n",
      "base_model.model.model.layers.52.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003411\n",
      "base_model.model.model.layers.52.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000554\n",
      "base_model.model.model.layers.53.self_attn.q_proj.lora_A.default.weight: mean=0.000015, std=0.006355\n",
      "base_model.model.model.layers.53.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000130\n",
      "base_model.model.model.layers.53.self_attn.k_proj.lora_A.default.weight: mean=-0.000003, std=0.006347\n",
      "base_model.model.model.layers.53.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000124\n",
      "base_model.model.model.layers.53.self_attn.v_proj.lora_A.default.weight: mean=-0.000003, std=0.006362\n",
      "base_model.model.model.layers.53.self_attn.v_proj.lora_B.default.weight: mean=-0.000004, std=0.000962\n",
      "base_model.model.model.layers.53.mlp.gate_proj.lora_A.default.weight: mean=-0.000001, std=0.006418\n",
      "base_model.model.model.layers.53.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000455\n",
      "base_model.model.model.layers.53.mlp.up_proj.lora_A.default.weight: mean=0.000009, std=0.006450\n",
      "base_model.model.model.layers.53.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000524\n",
      "base_model.model.model.layers.53.mlp.down_proj.lora_A.default.weight: mean=-0.000000, std=0.003409\n",
      "base_model.model.model.layers.53.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000532\n",
      "base_model.model.model.layers.54.self_attn.q_proj.lora_A.default.weight: mean=-0.000003, std=0.006353\n",
      "base_model.model.model.layers.54.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000126\n",
      "base_model.model.model.layers.54.self_attn.k_proj.lora_A.default.weight: mean=0.000010, std=0.006349\n",
      "base_model.model.model.layers.54.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000123\n",
      "base_model.model.model.layers.54.self_attn.v_proj.lora_A.default.weight: mean=0.000016, std=0.006364\n",
      "base_model.model.model.layers.54.self_attn.v_proj.lora_B.default.weight: mean=-0.000002, std=0.000903\n",
      "base_model.model.model.layers.54.mlp.gate_proj.lora_A.default.weight: mean=0.000011, std=0.006411\n",
      "base_model.model.model.layers.54.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000437\n",
      "base_model.model.model.layers.54.mlp.up_proj.lora_A.default.weight: mean=-0.000015, std=0.006434\n",
      "base_model.model.model.layers.54.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000501\n",
      "base_model.model.model.layers.54.mlp.down_proj.lora_A.default.weight: mean=-0.000002, std=0.003410\n",
      "base_model.model.model.layers.54.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000516\n",
      "base_model.model.model.layers.55.self_attn.q_proj.lora_A.default.weight: mean=0.000006, std=0.006355\n",
      "base_model.model.model.layers.55.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000134\n",
      "base_model.model.model.layers.55.self_attn.k_proj.lora_A.default.weight: mean=0.000003, std=0.006357\n",
      "base_model.model.model.layers.55.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000171\n",
      "base_model.model.model.layers.55.self_attn.v_proj.lora_A.default.weight: mean=0.000005, std=0.006365\n",
      "base_model.model.model.layers.55.self_attn.v_proj.lora_B.default.weight: mean=-0.000000, std=0.001010\n",
      "base_model.model.model.layers.55.mlp.gate_proj.lora_A.default.weight: mean=-0.000001, std=0.006413\n",
      "base_model.model.model.layers.55.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000435\n",
      "base_model.model.model.layers.55.mlp.up_proj.lora_A.default.weight: mean=0.000004, std=0.006440\n",
      "base_model.model.model.layers.55.mlp.up_proj.lora_B.default.weight: mean=-0.000001, std=0.000503\n",
      "base_model.model.model.layers.55.mlp.down_proj.lora_A.default.weight: mean=0.000002, std=0.003412\n",
      "base_model.model.model.layers.55.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000530\n",
      "base_model.model.model.layers.56.self_attn.q_proj.lora_A.default.weight: mean=0.000002, std=0.006358\n",
      "base_model.model.model.layers.56.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000153\n",
      "base_model.model.model.layers.56.self_attn.k_proj.lora_A.default.weight: mean=0.000009, std=0.006355\n",
      "base_model.model.model.layers.56.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000196\n",
      "base_model.model.model.layers.56.self_attn.v_proj.lora_A.default.weight: mean=-0.000007, std=0.006363\n",
      "base_model.model.model.layers.56.self_attn.v_proj.lora_B.default.weight: mean=0.000004, std=0.000938\n",
      "base_model.model.model.layers.56.mlp.gate_proj.lora_A.default.weight: mean=-0.000002, std=0.006418\n",
      "base_model.model.model.layers.56.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000441\n",
      "base_model.model.model.layers.56.mlp.up_proj.lora_A.default.weight: mean=-0.000017, std=0.006441\n",
      "base_model.model.model.layers.56.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000508\n",
      "base_model.model.model.layers.56.mlp.down_proj.lora_A.default.weight: mean=-0.000002, std=0.003412\n",
      "base_model.model.model.layers.56.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000570\n",
      "base_model.model.model.layers.57.self_attn.q_proj.lora_A.default.weight: mean=-0.000012, std=0.006349\n",
      "base_model.model.model.layers.57.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000142\n",
      "base_model.model.model.layers.57.self_attn.k_proj.lora_A.default.weight: mean=-0.000021, std=0.006359\n",
      "base_model.model.model.layers.57.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000152\n",
      "base_model.model.model.layers.57.self_attn.v_proj.lora_A.default.weight: mean=0.000001, std=0.006369\n",
      "base_model.model.model.layers.57.self_attn.v_proj.lora_B.default.weight: mean=0.000001, std=0.000918\n",
      "base_model.model.model.layers.57.mlp.gate_proj.lora_A.default.weight: mean=0.000011, std=0.006413\n",
      "base_model.model.model.layers.57.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000445\n",
      "base_model.model.model.layers.57.mlp.up_proj.lora_A.default.weight: mean=0.000003, std=0.006464\n",
      "base_model.model.model.layers.57.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000539\n",
      "base_model.model.model.layers.57.mlp.down_proj.lora_A.default.weight: mean=0.000001, std=0.003412\n",
      "base_model.model.model.layers.57.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000558\n",
      "base_model.model.model.layers.58.self_attn.q_proj.lora_A.default.weight: mean=-0.000004, std=0.006350\n",
      "base_model.model.model.layers.58.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000122\n",
      "base_model.model.model.layers.58.self_attn.k_proj.lora_A.default.weight: mean=-0.000008, std=0.006354\n",
      "base_model.model.model.layers.58.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000146\n",
      "base_model.model.model.layers.58.self_attn.v_proj.lora_A.default.weight: mean=0.000004, std=0.006363\n",
      "base_model.model.model.layers.58.self_attn.v_proj.lora_B.default.weight: mean=0.000003, std=0.000955\n",
      "base_model.model.model.layers.58.mlp.gate_proj.lora_A.default.weight: mean=0.000019, std=0.006415\n",
      "base_model.model.model.layers.58.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000429\n",
      "base_model.model.model.layers.58.mlp.up_proj.lora_A.default.weight: mean=-0.000008, std=0.006439\n",
      "base_model.model.model.layers.58.mlp.up_proj.lora_B.default.weight: mean=0.000001, std=0.000483\n",
      "base_model.model.model.layers.58.mlp.down_proj.lora_A.default.weight: mean=0.000002, std=0.003411\n",
      "base_model.model.model.layers.58.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000513\n",
      "base_model.model.model.layers.59.self_attn.q_proj.lora_A.default.weight: mean=0.000011, std=0.006357\n",
      "base_model.model.model.layers.59.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000098\n",
      "base_model.model.model.layers.59.self_attn.k_proj.lora_A.default.weight: mean=-0.000017, std=0.006346\n",
      "base_model.model.model.layers.59.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000127\n",
      "base_model.model.model.layers.59.self_attn.v_proj.lora_A.default.weight: mean=-0.000016, std=0.006366\n",
      "base_model.model.model.layers.59.self_attn.v_proj.lora_B.default.weight: mean=0.000002, std=0.000867\n",
      "base_model.model.model.layers.59.mlp.gate_proj.lora_A.default.weight: mean=-0.000004, std=0.006405\n",
      "base_model.model.model.layers.59.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000423\n",
      "base_model.model.model.layers.59.mlp.up_proj.lora_A.default.weight: mean=0.000034, std=0.006456\n",
      "base_model.model.model.layers.59.mlp.up_proj.lora_B.default.weight: mean=-0.000001, std=0.000518\n",
      "base_model.model.model.layers.59.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003417\n",
      "base_model.model.model.layers.59.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000594\n",
      "base_model.model.model.layers.60.self_attn.q_proj.lora_A.default.weight: mean=-0.000004, std=0.006362\n",
      "base_model.model.model.layers.60.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000175\n",
      "base_model.model.model.layers.60.self_attn.k_proj.lora_A.default.weight: mean=0.000001, std=0.006358\n",
      "base_model.model.model.layers.60.self_attn.k_proj.lora_B.default.weight: mean=-0.000001, std=0.000224\n",
      "base_model.model.model.layers.60.self_attn.v_proj.lora_A.default.weight: mean=0.000007, std=0.006369\n",
      "base_model.model.model.layers.60.self_attn.v_proj.lora_B.default.weight: mean=0.000002, std=0.000980\n",
      "base_model.model.model.layers.60.mlp.gate_proj.lora_A.default.weight: mean=0.000007, std=0.006410\n",
      "base_model.model.model.layers.60.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000435\n",
      "base_model.model.model.layers.60.mlp.up_proj.lora_A.default.weight: mean=-0.000018, std=0.006448\n",
      "base_model.model.model.layers.60.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000523\n",
      "base_model.model.model.layers.60.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003417\n",
      "base_model.model.model.layers.60.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000611\n",
      "base_model.model.model.layers.61.self_attn.q_proj.lora_A.default.weight: mean=-0.000009, std=0.006353\n",
      "base_model.model.model.layers.61.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000078\n",
      "base_model.model.model.layers.61.self_attn.k_proj.lora_A.default.weight: mean=-0.000010, std=0.006350\n",
      "base_model.model.model.layers.61.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000085\n",
      "base_model.model.model.layers.61.self_attn.v_proj.lora_A.default.weight: mean=-0.000001, std=0.006364\n",
      "base_model.model.model.layers.61.self_attn.v_proj.lora_B.default.weight: mean=-0.000001, std=0.000920\n",
      "base_model.model.model.layers.61.mlp.gate_proj.lora_A.default.weight: mean=-0.000008, std=0.006409\n",
      "base_model.model.model.layers.61.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000429\n",
      "base_model.model.model.layers.61.mlp.up_proj.lora_A.default.weight: mean=0.000010, std=0.006448\n",
      "base_model.model.model.layers.61.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000507\n",
      "base_model.model.model.layers.61.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003412\n",
      "base_model.model.model.layers.61.mlp.down_proj.lora_B.default.weight: mean=0.000002, std=0.000560\n",
      "base_model.model.model.layers.62.self_attn.q_proj.lora_A.default.weight: mean=-0.000011, std=0.006351\n",
      "base_model.model.model.layers.62.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000068\n",
      "base_model.model.model.layers.62.self_attn.k_proj.lora_A.default.weight: mean=-0.000004, std=0.006355\n",
      "base_model.model.model.layers.62.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000055\n",
      "base_model.model.model.layers.62.self_attn.v_proj.lora_A.default.weight: mean=-0.000013, std=0.006354\n",
      "base_model.model.model.layers.62.self_attn.v_proj.lora_B.default.weight: mean=-0.000001, std=0.000871\n",
      "base_model.model.model.layers.62.mlp.gate_proj.lora_A.default.weight: mean=0.000006, std=0.006423\n",
      "base_model.model.model.layers.62.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000433\n",
      "base_model.model.model.layers.62.mlp.up_proj.lora_A.default.weight: mean=0.000001, std=0.006444\n",
      "base_model.model.model.layers.62.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000490\n",
      "base_model.model.model.layers.62.mlp.down_proj.lora_A.default.weight: mean=-0.000002, std=0.003413\n",
      "base_model.model.model.layers.62.mlp.down_proj.lora_B.default.weight: mean=0.000002, std=0.000548\n",
      "base_model.model.model.layers.63.self_attn.q_proj.lora_A.default.weight: mean=-0.000001, std=0.006354\n",
      "base_model.model.model.layers.63.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000109\n",
      "base_model.model.model.layers.63.self_attn.k_proj.lora_A.default.weight: mean=-0.000007, std=0.006355\n",
      "base_model.model.model.layers.63.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000117\n",
      "base_model.model.model.layers.63.self_attn.v_proj.lora_A.default.weight: mean=-0.000004, std=0.006365\n",
      "base_model.model.model.layers.63.self_attn.v_proj.lora_B.default.weight: mean=0.000004, std=0.000931\n",
      "base_model.model.model.layers.63.mlp.gate_proj.lora_A.default.weight: mean=-0.000004, std=0.006413\n",
      "base_model.model.model.layers.63.mlp.gate_proj.lora_B.default.weight: mean=-0.000002, std=0.000434\n",
      "base_model.model.model.layers.63.mlp.up_proj.lora_A.default.weight: mean=-0.000003, std=0.006434\n",
      "base_model.model.model.layers.63.mlp.up_proj.lora_B.default.weight: mean=-0.000001, std=0.000478\n",
      "base_model.model.model.layers.63.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003420\n",
      "base_model.model.model.layers.63.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000630\n",
      "base_model.model.model.layers.64.self_attn.q_proj.lora_A.default.weight: mean=-0.000001, std=0.006354\n",
      "base_model.model.model.layers.64.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000142\n",
      "base_model.model.model.layers.64.self_attn.k_proj.lora_A.default.weight: mean=-0.000013, std=0.006355\n",
      "base_model.model.model.layers.64.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000158\n",
      "base_model.model.model.layers.64.self_attn.v_proj.lora_A.default.weight: mean=-0.000008, std=0.006374\n",
      "base_model.model.model.layers.64.self_attn.v_proj.lora_B.default.weight: mean=-0.000006, std=0.000961\n",
      "base_model.model.model.layers.64.mlp.gate_proj.lora_A.default.weight: mean=-0.000004, std=0.006415\n",
      "base_model.model.model.layers.64.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000437\n",
      "base_model.model.model.layers.64.mlp.up_proj.lora_A.default.weight: mean=-0.000008, std=0.006448\n",
      "base_model.model.model.layers.64.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000505\n",
      "base_model.model.model.layers.64.mlp.down_proj.lora_A.default.weight: mean=0.000000, std=0.003436\n",
      "base_model.model.model.layers.64.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000709\n",
      "base_model.model.model.layers.65.self_attn.q_proj.lora_A.default.weight: mean=-0.000011, std=0.006350\n",
      "base_model.model.model.layers.65.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000104\n",
      "base_model.model.model.layers.65.self_attn.k_proj.lora_A.default.weight: mean=0.000004, std=0.006347\n",
      "base_model.model.model.layers.65.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000109\n",
      "base_model.model.model.layers.65.self_attn.v_proj.lora_A.default.weight: mean=-0.000005, std=0.006362\n",
      "base_model.model.model.layers.65.self_attn.v_proj.lora_B.default.weight: mean=0.000003, std=0.000904\n",
      "base_model.model.model.layers.65.mlp.gate_proj.lora_A.default.weight: mean=0.000005, std=0.006412\n",
      "base_model.model.model.layers.65.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000438\n",
      "base_model.model.model.layers.65.mlp.up_proj.lora_A.default.weight: mean=0.000007, std=0.006443\n",
      "base_model.model.model.layers.65.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000498\n",
      "base_model.model.model.layers.65.mlp.down_proj.lora_A.default.weight: mean=-0.000001, std=0.003429\n",
      "base_model.model.model.layers.65.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000663\n",
      "base_model.model.model.layers.66.self_attn.q_proj.lora_A.default.weight: mean=0.000008, std=0.006352\n",
      "base_model.model.model.layers.66.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000088\n",
      "base_model.model.model.layers.66.self_attn.k_proj.lora_A.default.weight: mean=-0.000017, std=0.006346\n",
      "base_model.model.model.layers.66.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000101\n",
      "base_model.model.model.layers.66.self_attn.v_proj.lora_A.default.weight: mean=0.000004, std=0.006366\n",
      "base_model.model.model.layers.66.self_attn.v_proj.lora_B.default.weight: mean=0.000002, std=0.000901\n",
      "base_model.model.model.layers.66.mlp.gate_proj.lora_A.default.weight: mean=-0.000000, std=0.006411\n",
      "base_model.model.model.layers.66.mlp.gate_proj.lora_B.default.weight: mean=0.000001, std=0.000419\n",
      "base_model.model.model.layers.66.mlp.up_proj.lora_A.default.weight: mean=0.000010, std=0.006426\n",
      "base_model.model.model.layers.66.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000472\n",
      "base_model.model.model.layers.66.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003415\n",
      "base_model.model.model.layers.66.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000564\n",
      "base_model.model.model.layers.67.self_attn.q_proj.lora_A.default.weight: mean=-0.000001, std=0.006355\n",
      "base_model.model.model.layers.67.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000133\n",
      "base_model.model.model.layers.67.self_attn.k_proj.lora_A.default.weight: mean=0.000013, std=0.006354\n",
      "base_model.model.model.layers.67.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000148\n",
      "base_model.model.model.layers.67.self_attn.v_proj.lora_A.default.weight: mean=0.000019, std=0.006365\n",
      "base_model.model.model.layers.67.self_attn.v_proj.lora_B.default.weight: mean=0.000003, std=0.000813\n",
      "base_model.model.model.layers.67.mlp.gate_proj.lora_A.default.weight: mean=-0.000010, std=0.006418\n",
      "base_model.model.model.layers.67.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000439\n",
      "base_model.model.model.layers.67.mlp.up_proj.lora_A.default.weight: mean=-0.000013, std=0.006432\n",
      "base_model.model.model.layers.67.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000478\n",
      "base_model.model.model.layers.67.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003413\n",
      "base_model.model.model.layers.67.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000569\n",
      "base_model.model.model.layers.68.self_attn.q_proj.lora_A.default.weight: mean=0.000011, std=0.006357\n",
      "base_model.model.model.layers.68.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000158\n",
      "base_model.model.model.layers.68.self_attn.k_proj.lora_A.default.weight: mean=0.000000, std=0.006359\n",
      "base_model.model.model.layers.68.self_attn.k_proj.lora_B.default.weight: mean=0.000000, std=0.000193\n",
      "base_model.model.model.layers.68.self_attn.v_proj.lora_A.default.weight: mean=-0.000001, std=0.006361\n",
      "base_model.model.model.layers.68.self_attn.v_proj.lora_B.default.weight: mean=-0.000000, std=0.000888\n",
      "base_model.model.model.layers.68.mlp.gate_proj.lora_A.default.weight: mean=-0.000007, std=0.006420\n",
      "base_model.model.model.layers.68.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000446\n",
      "base_model.model.model.layers.68.mlp.up_proj.lora_A.default.weight: mean=-0.000004, std=0.006460\n",
      "base_model.model.model.layers.68.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000528\n",
      "base_model.model.model.layers.68.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003436\n",
      "base_model.model.model.layers.68.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000719\n",
      "base_model.model.model.layers.69.self_attn.q_proj.lora_A.default.weight: mean=0.000004, std=0.006351\n",
      "base_model.model.model.layers.69.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000139\n",
      "base_model.model.model.layers.69.self_attn.k_proj.lora_A.default.weight: mean=-0.000013, std=0.006355\n",
      "base_model.model.model.layers.69.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000166\n",
      "base_model.model.model.layers.69.self_attn.v_proj.lora_A.default.weight: mean=-0.000001, std=0.006367\n",
      "base_model.model.model.layers.69.self_attn.v_proj.lora_B.default.weight: mean=0.000003, std=0.000885\n",
      "base_model.model.model.layers.69.mlp.gate_proj.lora_A.default.weight: mean=0.000013, std=0.006410\n",
      "base_model.model.model.layers.69.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000419\n",
      "base_model.model.model.layers.69.mlp.up_proj.lora_A.default.weight: mean=0.000005, std=0.006441\n",
      "base_model.model.model.layers.69.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000486\n",
      "base_model.model.model.layers.69.mlp.down_proj.lora_A.default.weight: mean=0.000000, std=0.003426\n",
      "base_model.model.model.layers.69.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000647\n",
      "base_model.model.model.layers.70.self_attn.q_proj.lora_A.default.weight: mean=-0.000010, std=0.006363\n",
      "base_model.model.model.layers.70.self_attn.q_proj.lora_B.default.weight: mean=-0.000001, std=0.000199\n",
      "base_model.model.model.layers.70.self_attn.k_proj.lora_A.default.weight: mean=0.000009, std=0.006349\n",
      "base_model.model.model.layers.70.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000244\n",
      "base_model.model.model.layers.70.self_attn.v_proj.lora_A.default.weight: mean=-0.000003, std=0.006369\n",
      "base_model.model.model.layers.70.self_attn.v_proj.lora_B.default.weight: mean=-0.000000, std=0.000897\n",
      "base_model.model.model.layers.70.mlp.gate_proj.lora_A.default.weight: mean=0.000010, std=0.006414\n",
      "base_model.model.model.layers.70.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000424\n",
      "base_model.model.model.layers.70.mlp.up_proj.lora_A.default.weight: mean=-0.000002, std=0.006447\n",
      "base_model.model.model.layers.70.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000492\n",
      "base_model.model.model.layers.70.mlp.down_proj.lora_A.default.weight: mean=-0.000002, std=0.003422\n",
      "base_model.model.model.layers.70.mlp.down_proj.lora_B.default.weight: mean=-0.000002, std=0.000650\n",
      "base_model.model.model.layers.71.self_attn.q_proj.lora_A.default.weight: mean=0.000004, std=0.006364\n",
      "base_model.model.model.layers.71.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000286\n",
      "base_model.model.model.layers.71.self_attn.k_proj.lora_A.default.weight: mean=0.000000, std=0.006344\n",
      "base_model.model.model.layers.71.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000304\n",
      "base_model.model.model.layers.71.self_attn.v_proj.lora_A.default.weight: mean=0.000005, std=0.006368\n",
      "base_model.model.model.layers.71.self_attn.v_proj.lora_B.default.weight: mean=-0.000005, std=0.000852\n",
      "base_model.model.model.layers.71.mlp.gate_proj.lora_A.default.weight: mean=0.000002, std=0.006424\n",
      "base_model.model.model.layers.71.mlp.gate_proj.lora_B.default.weight: mean=-0.000001, std=0.000443\n",
      "base_model.model.model.layers.71.mlp.up_proj.lora_A.default.weight: mean=0.000000, std=0.006456\n",
      "base_model.model.model.layers.71.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000519\n",
      "base_model.model.model.layers.71.mlp.down_proj.lora_A.default.weight: mean=0.000002, std=0.003424\n",
      "base_model.model.model.layers.71.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000662\n",
      "base_model.model.model.layers.72.self_attn.q_proj.lora_A.default.weight: mean=-0.000006, std=0.006364\n",
      "base_model.model.model.layers.72.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000347\n",
      "base_model.model.model.layers.72.self_attn.k_proj.lora_A.default.weight: mean=0.000000, std=0.006356\n",
      "base_model.model.model.layers.72.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000349\n",
      "base_model.model.model.layers.72.self_attn.v_proj.lora_A.default.weight: mean=0.000004, std=0.006372\n",
      "base_model.model.model.layers.72.self_attn.v_proj.lora_B.default.weight: mean=-0.000006, std=0.000895\n",
      "base_model.model.model.layers.72.mlp.gate_proj.lora_A.default.weight: mean=-0.000005, std=0.006437\n",
      "base_model.model.model.layers.72.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000477\n",
      "base_model.model.model.layers.72.mlp.up_proj.lora_A.default.weight: mean=0.000012, std=0.006500\n",
      "base_model.model.model.layers.72.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000591\n",
      "base_model.model.model.layers.72.mlp.down_proj.lora_A.default.weight: mean=0.000004, std=0.003441\n",
      "base_model.model.model.layers.72.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000755\n",
      "base_model.model.model.layers.73.self_attn.q_proj.lora_A.default.weight: mean=-0.000003, std=0.006356\n",
      "base_model.model.model.layers.73.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000258\n",
      "base_model.model.model.layers.73.self_attn.k_proj.lora_A.default.weight: mean=-0.000007, std=0.006356\n",
      "base_model.model.model.layers.73.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000319\n",
      "base_model.model.model.layers.73.self_attn.v_proj.lora_A.default.weight: mean=-0.000005, std=0.006356\n",
      "base_model.model.model.layers.73.self_attn.v_proj.lora_B.default.weight: mean=-0.000002, std=0.000964\n",
      "base_model.model.model.layers.73.mlp.gate_proj.lora_A.default.weight: mean=-0.000005, std=0.006436\n",
      "base_model.model.model.layers.73.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000480\n",
      "base_model.model.model.layers.73.mlp.up_proj.lora_A.default.weight: mean=0.000002, std=0.006507\n",
      "base_model.model.model.layers.73.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000591\n",
      "base_model.model.model.layers.73.mlp.down_proj.lora_A.default.weight: mean=0.000003, std=0.003440\n",
      "base_model.model.model.layers.73.mlp.down_proj.lora_B.default.weight: mean=0.000001, std=0.000754\n",
      "base_model.model.model.layers.74.self_attn.q_proj.lora_A.default.weight: mean=0.000007, std=0.006369\n",
      "base_model.model.model.layers.74.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000288\n",
      "base_model.model.model.layers.74.self_attn.k_proj.lora_A.default.weight: mean=-0.000004, std=0.006364\n",
      "base_model.model.model.layers.74.self_attn.k_proj.lora_B.default.weight: mean=-0.000000, std=0.000320\n",
      "base_model.model.model.layers.74.self_attn.v_proj.lora_A.default.weight: mean=0.000004, std=0.006363\n",
      "base_model.model.model.layers.74.self_attn.v_proj.lora_B.default.weight: mean=-0.000001, std=0.000951\n",
      "base_model.model.model.layers.74.mlp.gate_proj.lora_A.default.weight: mean=0.000007, std=0.006455\n",
      "base_model.model.model.layers.74.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000508\n",
      "base_model.model.model.layers.74.mlp.up_proj.lora_A.default.weight: mean=-0.000004, std=0.006535\n",
      "base_model.model.model.layers.74.mlp.up_proj.lora_B.default.weight: mean=0.000000, std=0.000623\n",
      "base_model.model.model.layers.74.mlp.down_proj.lora_A.default.weight: mean=-0.000003, std=0.003444\n",
      "base_model.model.model.layers.74.mlp.down_proj.lora_B.default.weight: mean=0.000000, std=0.000767\n",
      "base_model.model.model.layers.75.self_attn.q_proj.lora_A.default.weight: mean=0.000003, std=0.006380\n",
      "base_model.model.model.layers.75.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000458\n",
      "base_model.model.model.layers.75.self_attn.k_proj.lora_A.default.weight: mean=-0.000006, std=0.006352\n",
      "base_model.model.model.layers.75.self_attn.k_proj.lora_B.default.weight: mean=0.000002, std=0.000429\n",
      "base_model.model.model.layers.75.self_attn.v_proj.lora_A.default.weight: mean=-0.000006, std=0.006363\n",
      "base_model.model.model.layers.75.self_attn.v_proj.lora_B.default.weight: mean=-0.000003, std=0.000933\n",
      "base_model.model.model.layers.75.mlp.gate_proj.lora_A.default.weight: mean=-0.000006, std=0.006494\n",
      "base_model.model.model.layers.75.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000569\n",
      "base_model.model.model.layers.75.mlp.up_proj.lora_A.default.weight: mean=0.000000, std=0.006617\n",
      "base_model.model.model.layers.75.mlp.up_proj.lora_B.default.weight: mean=-0.000001, std=0.000711\n",
      "base_model.model.model.layers.75.mlp.down_proj.lora_A.default.weight: mean=0.000001, std=0.003458\n",
      "base_model.model.model.layers.75.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000801\n",
      "base_model.model.model.layers.76.self_attn.q_proj.lora_A.default.weight: mean=-0.000012, std=0.006361\n",
      "base_model.model.model.layers.76.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000273\n",
      "base_model.model.model.layers.76.self_attn.k_proj.lora_A.default.weight: mean=0.000001, std=0.006362\n",
      "base_model.model.model.layers.76.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000329\n",
      "base_model.model.model.layers.76.self_attn.v_proj.lora_A.default.weight: mean=0.000003, std=0.006361\n",
      "base_model.model.model.layers.76.self_attn.v_proj.lora_B.default.weight: mean=-0.000001, std=0.000905\n",
      "base_model.model.model.layers.76.mlp.gate_proj.lora_A.default.weight: mean=-0.000003, std=0.006518\n",
      "base_model.model.model.layers.76.mlp.gate_proj.lora_B.default.weight: mean=0.000000, std=0.000599\n",
      "base_model.model.model.layers.76.mlp.up_proj.lora_A.default.weight: mean=0.000005, std=0.006683\n",
      "base_model.model.model.layers.76.mlp.up_proj.lora_B.default.weight: mean=0.000001, std=0.000744\n",
      "base_model.model.model.layers.76.mlp.down_proj.lora_A.default.weight: mean=-0.000012, std=0.003606\n",
      "base_model.model.model.layers.76.mlp.down_proj.lora_B.default.weight: mean=-0.000001, std=0.000929\n",
      "base_model.model.model.layers.77.self_attn.q_proj.lora_A.default.weight: mean=-0.000013, std=0.006358\n",
      "base_model.model.model.layers.77.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000283\n",
      "base_model.model.model.layers.77.self_attn.k_proj.lora_A.default.weight: mean=0.000004, std=0.006351\n",
      "base_model.model.model.layers.77.self_attn.k_proj.lora_B.default.weight: mean=0.000002, std=0.000358\n",
      "base_model.model.model.layers.77.self_attn.v_proj.lora_A.default.weight: mean=0.000009, std=0.006366\n",
      "base_model.model.model.layers.77.self_attn.v_proj.lora_B.default.weight: mean=-0.000003, std=0.000851\n",
      "base_model.model.model.layers.77.mlp.gate_proj.lora_A.default.weight: mean=-0.000001, std=0.006513\n",
      "base_model.model.model.layers.77.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000593\n",
      "base_model.model.model.layers.77.mlp.up_proj.lora_A.default.weight: mean=-0.000007, std=0.006653\n",
      "base_model.model.model.layers.77.mlp.up_proj.lora_B.default.weight: mean=-0.000001, std=0.000734\n",
      "base_model.model.model.layers.77.mlp.down_proj.lora_A.default.weight: mean=0.000000, std=0.003451\n",
      "base_model.model.model.layers.77.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000762\n",
      "base_model.model.model.layers.78.self_attn.q_proj.lora_A.default.weight: mean=-0.000016, std=0.006358\n",
      "base_model.model.model.layers.78.self_attn.q_proj.lora_B.default.weight: mean=0.000000, std=0.000204\n",
      "base_model.model.model.layers.78.self_attn.k_proj.lora_A.default.weight: mean=-0.000005, std=0.006355\n",
      "base_model.model.model.layers.78.self_attn.k_proj.lora_B.default.weight: mean=0.000001, std=0.000297\n",
      "base_model.model.model.layers.78.self_attn.v_proj.lora_A.default.weight: mean=-0.000009, std=0.006364\n",
      "base_model.model.model.layers.78.self_attn.v_proj.lora_B.default.weight: mean=-0.000001, std=0.000825\n",
      "base_model.model.model.layers.78.mlp.gate_proj.lora_A.default.weight: mean=0.000009, std=0.006557\n",
      "base_model.model.model.layers.78.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000637\n",
      "base_model.model.model.layers.78.mlp.up_proj.lora_A.default.weight: mean=0.000007, std=0.006671\n",
      "base_model.model.model.layers.78.mlp.up_proj.lora_B.default.weight: mean=0.000001, std=0.000755\n",
      "base_model.model.model.layers.78.mlp.down_proj.lora_A.default.weight: mean=0.000001, std=0.003475\n",
      "base_model.model.model.layers.78.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000794\n",
      "base_model.model.model.layers.79.self_attn.q_proj.lora_A.default.weight: mean=0.000002, std=0.006361\n",
      "base_model.model.model.layers.79.self_attn.q_proj.lora_B.default.weight: mean=-0.000000, std=0.000188\n",
      "base_model.model.model.layers.79.self_attn.k_proj.lora_A.default.weight: mean=-0.000012, std=0.006353\n",
      "base_model.model.model.layers.79.self_attn.k_proj.lora_B.default.weight: mean=-0.000002, std=0.000183\n",
      "base_model.model.model.layers.79.self_attn.v_proj.lora_A.default.weight: mean=-0.000004, std=0.006355\n",
      "base_model.model.model.layers.79.self_attn.v_proj.lora_B.default.weight: mean=0.000004, std=0.000692\n",
      "base_model.model.model.layers.79.mlp.gate_proj.lora_A.default.weight: mean=-0.000004, std=0.006502\n",
      "base_model.model.model.layers.79.mlp.gate_proj.lora_B.default.weight: mean=-0.000000, std=0.000609\n",
      "base_model.model.model.layers.79.mlp.up_proj.lora_A.default.weight: mean=0.000002, std=0.006530\n",
      "base_model.model.model.layers.79.mlp.up_proj.lora_B.default.weight: mean=-0.000000, std=0.000676\n",
      "base_model.model.model.layers.79.mlp.down_proj.lora_A.default.weight: mean=-0.000000, std=0.003442\n",
      "base_model.model.model.layers.79.mlp.down_proj.lora_B.default.weight: mean=-0.000000, std=0.000801\n"
     ]
    }
   ],
   "source": [
    "# First, let's see what LoRA keys we have in the current model\n",
    "lora_state_dict = {k: v for k, v in model.state_dict().items() if 'lora' in k}\n",
    "print(\"Number of LoRA parameters in model:\", len(lora_state_dict))\n",
    "print(\"First few LoRA keys in model:\", list(lora_state_dict.keys())[:3])\n",
    "\n",
    "# Now let's see what LoRA keys we have in the loaded weights\n",
    "lora_tensors = {k: v for k, v in tensors.items() if 'lora' in k}\n",
    "print(\"\\nNumber of LoRA parameters in loaded weights:\", len(lora_tensors))\n",
    "print(\"First few LoRA keys in loaded weights:\", list(lora_tensors.keys())[:3])\n",
    "\n",
    "# Load only the LoRA weights\n",
    "missing_keys = []\n",
    "mismatched_keys = []\n",
    "\n",
    "for k in lora_state_dict.keys():\n",
    "    if k in lora_tensors:\n",
    "        if lora_state_dict[k].shape == lora_tensors[k].shape:\n",
    "            lora_state_dict[k] = lora_tensors[k]\n",
    "        else:\n",
    "            mismatched_keys.append(f\"{k}: expected {lora_state_dict[k].shape}, got {lora_tensors[k].shape}\")\n",
    "    else:\n",
    "        missing_keys.append(k)\n",
    "\n",
    "# Print any issues found\n",
    "if missing_keys:\n",
    "    print(\"\\nWarning: Missing keys in trained weights:\", missing_keys[:5], \"...\")\n",
    "if mismatched_keys:\n",
    "    print(\"\\nWarning: Mismatched shapes:\", mismatched_keys[:5], \"...\")\n",
    "\n",
    "# Load only the LoRA weights\n",
    "model.load_state_dict(lora_state_dict, strict=False)\n",
    "\n",
    "# Verify the loading\n",
    "def verify_lora_loading():\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lora' in name:\n",
    "            if torch.all(param == 0):\n",
    "                print(f\"Warning: {name} appears to be all zeros!\")\n",
    "            else:\n",
    "                print(f\"{name}: mean={param.mean().item():.6f}, std={param.std().item():.6f}\")\n",
    "\n",
    "print(\"\\nVerifying LoRA weights:\")\n",
    "verify_lora_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47b2395-3aee-4885-b274-cef0c86c8981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['base_model.model.lm_head.weight', 'base_model.model.model.embed_tokens.weight', 'base_model.model.model.layers.0.input_layernorm.weight', 'base_model.model.model.layers.0.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight']\n"
     ]
    }
   ],
   "source": [
    "print(list(tensors.keys())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59ea0b-68e4-457e-9c0f-1804b327794c",
   "metadata": {},
   "source": [
    "And now, since we have a regular PEFT model, we can save using the built-in methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21096cf2-9270-478a-b7f8-9de70827c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"lora_adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f24feebb-4928-4d1b-aa0a-b8f86e623336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2914159\n",
      "drwxrwxrwx 2 root root    3000277 Oct 27 08:22 .\n",
      "drwxrwxrwx 9 root root    3004134 Oct 27 08:26 ..\n",
      "-rw-rw-rw- 1 root root       5115 Oct 27 08:22 README.md\n",
      "-rw-rw-rw- 1 root root        729 Oct 27 08:22 adapter_config.json\n",
      "-rw-rw-rw- 1 root root 2978086976 Oct 27 08:22 adapter_model.safetensors\n"
     ]
    }
   ],
   "source": [
    "!ls -al lora_adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7559253-4224-4be6-848d-2cb24a10ed54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2022.12.7)\n",
      "Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, fsspec, huggingface-hub\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed fsspec-2024.10.0 huggingface-hub-0.26.1 tqdm-4.66.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c945a4d-f8a7-419f-aad0-8ba49011fa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8e87bfebf04d9b9a51043e0bb45597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0881d87-4c0d-40f8-9693-ab1eb594951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad1300e9-4beb-47e3-ba87-3616e8cd819d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06b6b0f197f4f81811faaebf3c057a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sandbox-ai/Tango-70b/commit/104ad6ceeb55143e6e93fb172df0b5a59c16f768', commit_message='Upload model', commit_description='', oid='104ad6ceeb55143e6e93fb172df0b5a59c16f768', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sandbox-ai/Tango-70b', endpoint='https://huggingface.co', repo_type='model', repo_id='sandbox-ai/Tango-70b'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('sandbox-ai/Tango-70b') # If you want to share your model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1a514-df22-4fb2-90b9-6fd871e3c9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90a7a5e6-b343-489e-b44b-33847d1e76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lighteval[accelerate]\n",
      "  Using cached lighteval-0.6.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting transformers>=4.38.0 (from lighteval[accelerate])\n",
      "  Using cached transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate]) (0.26.1)\n",
      "Requirement already satisfied: torch<2.5,>=2.0 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate]) (2.1.0+cu118)\n",
      "Collecting GitPython>=3.1.41 (from lighteval[accelerate])\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting datasets>=2.14.0 (from lighteval[accelerate])\n",
      "  Using cached datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting termcolor==2.3.0 (from lighteval[accelerate])\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pytablewriter (from lighteval[accelerate])\n",
      "  Using cached pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting colorama (from lighteval[accelerate])\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting aenum==3.1.15 (from lighteval[accelerate])\n",
      "  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting nltk==3.9.1 (from lighteval[accelerate])\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting scikit-learn (from lighteval[accelerate])\n",
      "  Using cached scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting spacy==3.7.2 (from lighteval[accelerate])\n",
      "  Using cached spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting sacrebleu (from lighteval[accelerate])\n",
      "  Using cached sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting rouge-score==0.1.2 (from lighteval[accelerate])\n",
      "  Using cached rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece>=0.1.99 (from lighteval[accelerate])\n",
      "  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting protobuf==3.20.* (from lighteval[accelerate])\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Collecting pycountry (from lighteval[accelerate])\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: fsspec>=2023.12.2 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate]) (2024.10.0)\n",
      "Collecting accelerate (from lighteval[accelerate])\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting click (from nltk==3.9.1->lighteval[accelerate])\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk==3.9.1->lighteval[accelerate])\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk==3.9.1->lighteval[accelerate])\n",
      "  Using cached regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval[accelerate]) (4.66.5)\n",
      "Collecting absl-py (from rouge-score==0.1.2->lighteval[accelerate])\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->lighteval[accelerate]) (1.24.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score==0.1.2->lighteval[accelerate]) (1.16.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate]) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate]) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate]) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate]) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached langcodes-3.4.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval[accelerate]) (3.9.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.12.2 (from lighteval[accelerate])\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval[accelerate]) (6.0.1)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.1.41->lighteval[accelerate])\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->lighteval[accelerate]) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval[accelerate]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval[accelerate]) (3.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval[accelerate]) (2.1.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.38.0->lighteval[accelerate])\n",
      "  Using cached safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.38.0->lighteval[accelerate])\n",
      "  Using cached tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->lighteval[accelerate]) (5.9.6)\n",
      "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lighteval[accelerate])\n",
      "  Using cached DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lighteval[accelerate])\n",
      "  Using cached mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lighteval[accelerate])\n",
      "  Using cached pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lighteval[accelerate])\n",
      "  Using cached tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lighteval[accelerate])\n",
      "  Using cached tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval[accelerate])\n",
      "  Using cached typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting portalocker (from sacrebleu->lighteval[accelerate])\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu->lighteval[accelerate])\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lighteval[accelerate]) (4.9.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->lighteval[accelerate])\n",
      "  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->lighteval[accelerate])\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval[accelerate]) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached yarl-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (63 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.1.41->lighteval[accelerate])\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lighteval[accelerate])\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.23.0->lighteval[accelerate])\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval[accelerate]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval[accelerate]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval[accelerate]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval[accelerate]) (2022.12.7)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval[accelerate]) (2.8.2)\n",
      "Collecting pytz>=2018.9 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval[accelerate])\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.7.2->lighteval[accelerate]) (2.1.2)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.5,>=2.0->lighteval[accelerate]) (1.3.0)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.2->lighteval[accelerate])\n",
      "  Using cached marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.14.0->lighteval[accelerate])\n",
      "  Using cached propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Using cached aenum-3.1.15-py3-none-any.whl (137 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Using cached spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Using cached datasets-3.0.2-py3-none-any.whl (472 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached transformers-4.46.0-py3-none-any.whl (10.0 MB)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached lighteval-0.6.2-py3-none-any.whl (335 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.4.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Downloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
      "Downloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=14108fae2df6e6347658d670108ddc948700e07713b9ae7d5c8b2d8cb00c54ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: sentencepiece, pytz, cymem, aenum, xxhash, wasabi, tzdata, typing-extensions, threadpoolctl, termcolor, tcolorpy, tabulate, spacy-loggers, spacy-legacy, smmap, smart-open, scipy, safetensors, requests, regex, pycountry, pyarrow, protobuf, propcache, portalocker, pathvalidate, murmurhash, marisa-trie, joblib, fsspec, frozenlist, dill, colorama, click, chardet, catalogue, blis, async-timeout, annotated-types, aiohappyeyeballs, absl-py, typer, srsly, scikit-learn, sacrebleu, pydantic-core, preshed, pandas, nltk, multiprocess, multidict, mbstrdecoder, language-data, gitdb, cloudpathlib, aiosignal, yarl, typepy, tokenizers, rouge-score, pydantic, langcodes, GitPython, accelerate, transformers, confection, aiohttp, weasel, thinc, DataProperty, tabledata, spacy, datasets, pytablewriter, lighteval\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "Successfully installed DataProperty-1.0.1 GitPython-3.1.43 absl-py-2.1.0 accelerate-1.0.1 aenum-3.1.15 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 blis-0.7.11 catalogue-2.0.10 chardet-5.2.0 click-8.1.7 cloudpathlib-0.16.0 colorama-0.4.6 confection-0.1.5 cymem-2.0.8 datasets-3.0.2 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.9.0 gitdb-4.0.11 joblib-1.4.2 langcodes-3.4.1 language-data-1.2.0 lighteval-0.6.2 marisa-trie-1.2.1 mbstrdecoder-1.1.3 multidict-6.1.0 multiprocess-0.70.16 murmurhash-1.0.10 nltk-3.9.1 pandas-2.2.3 pathvalidate-3.2.1 portalocker-2.10.1 preshed-3.0.9 propcache-0.2.0 protobuf-3.20.3 pyarrow-17.0.0 pycountry-24.6.1 pydantic-2.9.2 pydantic-core-2.23.4 pytablewriter-1.2.0 pytz-2024.2 regex-2024.9.11 requests-2.32.3 rouge-score-0.1.2 sacrebleu-2.4.3 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 sentencepiece-0.2.0 smart-open-6.4.0 smmap-5.0.1 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 tabledata-1.3.3 tabulate-0.9.0 tcolorpy-0.1.6 termcolor-2.3.0 thinc-8.2.5 threadpoolctl-3.5.0 tokenizers-0.20.1 transformers-4.46.0 typepy-1.3.2 typer-0.9.4 typing-extensions-4.12.2 tzdata-2024.2 wasabi-1.1.3 weasel-0.3.4 xxhash-3.5.0 yarl-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lighteval[accelerate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1a1d32b-e356-4861-984c-04abb8b6d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lighteval in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
      "Requirement already satisfied: transformers>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from lighteval) (4.46.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from lighteval) (0.26.1)\n",
      "Requirement already satisfied: torch<2.5,>=2.0 in /usr/local/lib/python3.10/dist-packages (from lighteval) (2.1.0+cu118)\n",
      "Requirement already satisfied: GitPython>=3.1.41 in /usr/local/lib/python3.10/dist-packages (from lighteval) (3.1.43)\n",
      "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from lighteval) (3.0.2)\n",
      "Requirement already satisfied: termcolor==2.3.0 in /usr/local/lib/python3.10/dist-packages (from lighteval) (2.3.0)\n",
      "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lighteval) (1.2.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from lighteval) (0.4.6)\n",
      "Requirement already satisfied: aenum==3.1.15 in /usr/local/lib/python3.10/dist-packages (from lighteval) (3.1.15)\n",
      "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.10/dist-packages (from lighteval) (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lighteval) (1.5.2)\n",
      "Requirement already satisfied: spacy==3.7.2 in /usr/local/lib/python3.10/dist-packages (from lighteval) (3.7.2)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from lighteval) (2.4.3)\n",
      "Requirement already satisfied: rouge-score==0.1.2 in /usr/local/lib/python3.10/dist-packages (from lighteval) (0.1.2)\n",
      "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.10/dist-packages (from lighteval) (0.2.0)\n",
      "Requirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.10/dist-packages (from lighteval) (3.20.3)\n",
      "Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from lighteval) (24.6.1)\n",
      "Requirement already satisfied: fsspec>=2023.12.2 in /usr/local/lib/python3.10/dist-packages (from lighteval) (2024.9.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval) (4.66.5)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->lighteval) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->lighteval) (1.24.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score==0.1.2->lighteval) (1.16.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (6.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (3.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (3.10.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (6.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=3.1.41->lighteval) (4.0.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->lighteval) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval) (3.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval) (2.1.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->lighteval) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->lighteval) (0.20.1)\n",
      "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval) (1.0.1)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval) (1.1.3)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval) (3.2.1)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval) (1.3.3)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval) (0.1.6)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval) (1.3.2)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lighteval) (2.10.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lighteval) (0.9.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lighteval) (4.9.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lighteval) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lighteval) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval) (4.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.41->lighteval) (5.0.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.7.2->lighteval) (1.2.0)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lighteval) (5.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->lighteval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->lighteval) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->lighteval) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->lighteval) (0.1.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval) (2024.2)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.2->lighteval) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.7.2->lighteval) (2.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.0->lighteval) (2024.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.5,>=2.0->lighteval) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.2->lighteval) (1.2.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.14.0->lighteval) (0.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lighteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76e9725e-9073-4990-baf4-ff4effafc9c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lighteval.logging'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlighteval\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlighteval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation_tracker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluationTracker\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlighteval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VLLMModelConfig\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlighteval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelismManager, Pipeline, PipelineParameters\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lighteval.logging'"
     ]
    }
   ],
   "source": [
    "\n",
    "import lighteval\n",
    "from lighteval.logging.evaluation_tracker import EvaluationTracker\n",
    "from lighteval.models.model_config import VLLMModelConfig\n",
    "from lighteval.pipeline import ParallelismManager, Pipeline, PipelineParameters\n",
    "from lighteval.utils.utils import EnvConfig\n",
    "from lighteval.utils.imports import is_accelerate_available\n",
    "\n",
    "if is_accelerate_available():\n",
    "    from accelerate import Accelerator, InitProcessGroupKwargs\n",
    "    accelerator = Accelerator(kwargs_handlers=[InitProcessGroupKwargs(timeout=timedelta(seconds=3000))])\n",
    "else:\n",
    "    accelerator = None\n",
    "\n",
    "def main():\n",
    "    evaluation_tracker = EvaluationTracker(\n",
    "        output_dir=\"./results\",\n",
    "        save_details=True,\n",
    "        push_to_hub=True,\n",
    "        hub_results_org=\"sandbox-ai\",\n",
    "    )\n",
    "\n",
    "    pipeline_params = PipelineParameters(\n",
    "        launcher_type=ParallelismManager.ACCELERATE,\n",
    "        env_config=EnvConfig(cache_dir=\"tmp/\"),\n",
    "        # Remove the 2 parameters below once your configuration is tested\n",
    "        override_batch_size=1,\n",
    "        max_samples=10 \n",
    "    )\n",
    "\n",
    "    model_config = VLLMModelConfig(\n",
    "            pretrained=\"sandbox-ai/Tango-70b\",\n",
    "            dtype=\"float16\",\n",
    "            use_chat_template=True,\n",
    "    )\n",
    "\n",
    "    task = \"helm|mmlu|5|1\"\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        tasks=task,\n",
    "        pipeline_parameters=pipeline_params,\n",
    "        evaluation_tracker=evaluation_tracker,\n",
    "        model_config=model_config,\n",
    "        custom_task_directory=None, # if using a custom task\n",
    "    )\n",
    "\n",
    "    pipeline.evaluate()\n",
    "    pipeline.save_and_push_results()\n",
    "    pipeline.show_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cba3b933-942a-4cc5-afee-a159cd6d61a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'lighteval'...\n",
      "remote: Enumerating objects: 9451, done.\u001b[K\n",
      "remote: Counting objects: 100% (2283/2283), done.\u001b[K\n",
      "remote: Compressing objects: 100% (299/299), done.\u001b[K\n",
      "remote: Total 9451 (delta 2118), reused 1986 (delta 1980), pack-reused 7168 (from 1)\u001b[K\n",
      "Receiving objects: 100% (9451/9451), 2.36 MiB | 3.71 MiB/s, done.\n",
      "Resolving deltas: 100% (6212/6212), done.\n",
      "Updating files: 100% (170/170), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/lighteval.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f4c99bc-9d95-4c1f-b284-9305f7781904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lighteval[accelerate,adapters,logging,quantization] in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
      "\u001b[33mWARNING: lighteval 0.6.2 does not provide the extra 'logging'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (4.46.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (0.26.1)\n",
      "Requirement already satisfied: torch<2.5,>=2.0 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (2.1.0+cu118)\n",
      "Requirement already satisfied: GitPython>=3.1.41 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (3.1.43)\n",
      "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (3.0.2)\n",
      "Requirement already satisfied: termcolor==2.3.0 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (2.3.0)\n",
      "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (1.2.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (0.4.6)\n",
      "Requirement already satisfied: aenum==3.1.15 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (3.1.15)\n",
      "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (1.5.2)\n",
      "Requirement already satisfied: spacy==3.7.2 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (3.7.2)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (2.4.3)\n",
      "Requirement already satisfied: rouge-score==0.1.2 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (0.1.2)\n",
      "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (0.2.0)\n",
      "Requirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (3.20.3)\n",
      "Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (24.6.1)\n",
      "Requirement already satisfied: fsspec>=2023.12.2 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (2024.9.0)\n",
      "Requirement already satisfied: peft==0.3.0 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (0.3.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (1.0.1)\n",
      "Requirement already satisfied: bitsandbytes>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (0.44.1)\n",
      "Requirement already satisfied: auto-gptq>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from lighteval[accelerate,adapters,logging,quantization]) (0.4.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval[accelerate,adapters,logging,quantization]) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval[accelerate,adapters,logging,quantization]) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval[accelerate,adapters,logging,quantization]) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval[accelerate,adapters,logging,quantization]) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0->lighteval[accelerate,adapters,logging,quantization]) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0->lighteval[accelerate,adapters,logging,quantization]) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0->lighteval[accelerate,adapters,logging,quantization]) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0->lighteval[accelerate,adapters,logging,quantization]) (6.0.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->lighteval[accelerate,adapters,logging,quantization]) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score==0.1.2->lighteval[accelerate,adapters,logging,quantization]) (1.16.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (6.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (68.2.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (3.4.1)\n",
      "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq>=0.4.2->lighteval[accelerate,adapters,logging,quantization]) (1.0.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq>=0.4.2->lighteval[accelerate,adapters,logging,quantization]) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (3.10.10)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=3.1.41->lighteval[accelerate,adapters,logging,quantization]) (4.0.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->lighteval[accelerate,adapters,logging,quantization]) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval[accelerate,adapters,logging,quantization]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval[accelerate,adapters,logging,quantization]) (3.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval[accelerate,adapters,logging,quantization]) (2.1.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->lighteval[accelerate,adapters,logging,quantization]) (0.20.1)\n",
      "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval[accelerate,adapters,logging,quantization]) (1.0.1)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval[accelerate,adapters,logging,quantization]) (1.1.3)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval[accelerate,adapters,logging,quantization]) (3.2.1)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval[accelerate,adapters,logging,quantization]) (1.3.3)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lighteval[accelerate,adapters,logging,quantization]) (0.1.6)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval[accelerate,adapters,logging,quantization]) (1.3.2)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lighteval[accelerate,adapters,logging,quantization]) (2.10.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lighteval[accelerate,adapters,logging,quantization]) (0.9.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lighteval[accelerate,adapters,logging,quantization]) (4.9.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lighteval[accelerate,adapters,logging,quantization]) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lighteval[accelerate,adapters,logging,quantization]) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (4.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.41->lighteval[accelerate,adapters,logging,quantization]) (5.0.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (1.2.0)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lighteval[accelerate,adapters,logging,quantization]) (5.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (0.1.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval[accelerate,adapters,logging,quantization]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval[accelerate,adapters,logging,quantization]) (2024.2)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (2.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (2024.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.5,>=2.0->lighteval[accelerate,adapters,logging,quantization]) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.2->lighteval[accelerate,adapters,logging,quantization]) (1.2.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.14.0->lighteval[accelerate,adapters,logging,quantization]) (0.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install 'lighteval[accelerate,quantization,adapters,logging]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d410d5-e437-4f14-b011-9249ce3ca81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c11200-71e1-47d9-85a2-bf721d37b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed0545-142b-43dc-98bd-208178039ea4",
   "metadata": {},
   "source": [
    "Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f809f-09e3-4890-a262-8477490330b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e998ead-a480-45f4-bdbc-97546aa7b47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu118)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.46.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate, peft\n",
      "Successfully installed accelerate-1.0.1 peft-0.13.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a051373-ba24-4cee-b039-69e13dd18836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (0.26.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff1247d7-8407-465b-89c6-3fcbd791c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==2.1.0 (from -r ../requirements.txt (line 1))\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: accelerate==1.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 2)) (1.0.1)\n",
      "Collecting aiohappyeyeballs==2.4.3 (from -r ../requirements.txt (line 3))\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiohttp==3.10.10 (from -r ../requirements.txt (line 4))\n",
      "  Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiosignal==1.3.1 (from -r ../requirements.txt (line 5))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting annotated-types==0.7.0 (from -r ../requirements.txt (line 6))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.3 (from -r ../requirements.txt (line 7))\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting anyio==4.6.2.post1 (from -r ../requirements.txt (line 8))\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting appdirs==1.4.4 (from -r ../requirements.txt (line 9))\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: asttokens==2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 10)) (2.4.1)\n",
      "Collecting async-timeout==4.0.3 (from -r ../requirements.txt (line 11))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting attrs==24.2.0 (from -r ../requirements.txt (line 12))\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting backoff==2.2.1 (from -r ../requirements.txt (line 13))\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting beautifulsoup4==4.12.3 (from -r ../requirements.txt (line 14))\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bitsandbytes==0.44.1 (from -r ../requirements.txt (line 15))\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting black==24.10.0 (from -r ../requirements.txt (line 16))\n",
      "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting boltons==21.0.0 (from -r ../requirements.txt (line 17))\n",
      "  Downloading boltons-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting bracex==2.5.post1 (from -r ../requirements.txt (line 18))\n",
      "  Downloading bracex-2.5.post1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting Brotli==1.1.0 (from -r ../requirements.txt (line 19))\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cachetools==5.5.0 (from -r ../requirements.txt (line 20))\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting certifi==2024.8.30 (from -r ../requirements.txt (line 21))\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cffi==1.17.1 (from -r ../requirements.txt (line 22))\n",
      "  Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting chardet==5.2.0 (from -r ../requirements.txt (line 23))\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting charset-normalizer==3.4.0 (from -r ../requirements.txt (line 24))\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting click==8.1.7 (from -r ../requirements.txt (line 25))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting click-option-group==0.5.6 (from -r ../requirements.txt (line 26))\n",
      "  Downloading click_option_group-0.5.6-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting codeshield==1.0.1 (from -r ../requirements.txt (line 27))\n",
      "  Downloading codeshield-1.0.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting colorama==0.4.6 (from -r ../requirements.txt (line 28))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting coloredlogs==15.0.1 (from -r ../requirements.txt (line 29))\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting contourpy==1.3.0 (from -r ../requirements.txt (line 30))\n",
      "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cryptography==43.0.3 (from -r ../requirements.txt (line 31))\n",
      "  Downloading cryptography-43.0.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler==0.12.1 (from -r ../requirements.txt (line 32))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dataclasses-json==0.6.7 (from -r ../requirements.txt (line 33))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting datasets==3.0.1 (from -r ../requirements.txt (line 34))\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator==5.1.1 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 35)) (5.1.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 36)) (0.7.1)\n",
      "Collecting Deprecated==1.2.14 (from -r ../requirements.txt (line 37))\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dill==0.3.8 (from -r ../requirements.txt (line 38))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting distro==1.9.0 (from -r ../requirements.txt (line 39))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting effdet==0.4.1 (from -r ../requirements.txt (line 40))\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting emoji==2.14.0 (from -r ../requirements.txt (line 41))\n",
      "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting eval_type_backport==0.2.0 (from -r ../requirements.txt (line 42))\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting evaluate==0.4.3 (from -r ../requirements.txt (line 43))\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting exceptiongroup==1.2.2 (from -r ../requirements.txt (line 44))\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting executing==2.1.0 (from -r ../requirements.txt (line 45))\n",
      "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting face==22.0.0 (from -r ../requirements.txt (line 46))\n",
      "  Downloading face-22.0.0-py3-none-any.whl.metadata (816 bytes)\n",
      "Collecting faiss-gpu==1.7.2 (from -r ../requirements.txt (line 47))\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting fastcore==1.7.19 (from -r ../requirements.txt (line 48))\n",
      "  Downloading fastcore-1.7.19-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting filelock==3.16.1 (from -r ../requirements.txt (line 49))\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting filetype==1.2.0 (from -r ../requirements.txt (line 50))\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fire==0.7.0 (from -r ../requirements.txt (line 51))\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting flatbuffers==24.3.25 (from -r ../requirements.txt (line 52))\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting fonttools==4.54.1 (from -r ../requirements.txt (line 53))\n",
      "  Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.7/163.7 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist==1.4.1 (from -r ../requirements.txt (line 54))\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting fsspec==2024.6.1 (from -r ../requirements.txt (line 55))\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting glom==22.1.0 (from -r ../requirements.txt (line 56))\n",
      "  Downloading glom-22.1.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting google-api-core==2.21.0 (from -r ../requirements.txt (line 57))\n",
      "  Downloading google_api_core-2.21.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting google-auth==2.35.0 (from -r ../requirements.txt (line 58))\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-cloud-vision==3.7.4 (from -r ../requirements.txt (line 59))\n",
      "  Downloading google_cloud_vision-3.7.4-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting googleapis-common-protos==1.65.0 (from -r ../requirements.txt (line 60))\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting grpcio==1.67.0 (from -r ../requirements.txt (line 61))\n",
      "  Downloading grpcio-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting grpcio-status==1.62.3 (from -r ../requirements.txt (line 62))\n",
      "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting h11==0.14.0 (from -r ../requirements.txt (line 63))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httpcore==1.0.6 (from -r ../requirements.txt (line 64))\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting httpx==0.27.2 (from -r ../requirements.txt (line 65))\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub==0.26.0 (from -r ../requirements.txt (line 66))\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting humanfriendly==10.0 (from -r ../requirements.txt (line 67))\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting idna==3.10 (from -r ../requirements.txt (line 68))\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting importlib_metadata==7.1.0 (from -r ../requirements.txt (line 69))\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting inflate64==1.0.0 (from -r ../requirements.txt (line 70))\n",
      "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting iopath==0.1.10 (from -r ../requirements.txt (line 71))\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ipython==8.28.0 (from -r ../requirements.txt (line 72))\n",
      "  Downloading ipython-8.28.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jedi==0.19.1 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 73)) (0.19.1)\n",
      "Collecting Jinja2==3.1.4 (from -r ../requirements.txt (line 74))\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib==1.4.2 (from -r ../requirements.txt (line 75))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting jsonpath-python==1.0.6 (from -r ../requirements.txt (line 76))\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jsonschema==4.23.0 (from -r ../requirements.txt (line 77))\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonschema-specifications==2024.10.1 (from -r ../requirements.txt (line 78))\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting kiwisolver==1.4.7 (from -r ../requirements.txt (line 79))\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting langdetect==1.0.9 (from -r ../requirements.txt (line 80))\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting layoutparser==0.3.4 (from -r ../requirements.txt (line 81))\n",
      "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting llama-recipes==0.0.4.post1 (from -r ../requirements.txt (line 82))\n",
      "  Downloading llama_recipes-0.0.4.post1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting loralib==0.1.2 (from -r ../requirements.txt (line 83))\n",
      "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting lxml==5.3.0 (from -r ../requirements.txt (line 84))\n",
      "  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting markdown-it-py==3.0.0 (from -r ../requirements.txt (line 85))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting MarkupSafe==3.0.2 (from -r ../requirements.txt (line 86))\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting marshmallow==3.23.0 (from -r ../requirements.txt (line 87))\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting matplotlib==3.9.2 (from -r ../requirements.txt (line 88))\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting matplotlib-inline==0.1.7 (from -r ../requirements.txt (line 89))\n",
      "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting mdurl==0.1.2 (from -r ../requirements.txt (line 90))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 91)) (1.3.0)\n",
      "Collecting multidict==6.1.0 (from -r ../requirements.txt (line 92))\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting multiprocess==0.70.16 (from -r ../requirements.txt (line 93))\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting multivolumefile==0.2.3 (from -r ../requirements.txt (line 94))\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting mypy-extensions==1.0.0 (from -r ../requirements.txt (line 95))\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting nest-asyncio==1.6.0 (from -r ../requirements.txt (line 96))\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting networkx==3.4.1 (from -r ../requirements.txt (line 97))\n",
      "  Downloading networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nltk==3.9.1 (from -r ../requirements.txt (line 98))\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy==1.26.4 (from -r ../requirements.txt (line 99))\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from -r ../requirements.txt (line 100))\n",
      "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from -r ../requirements.txt (line 101))\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from -r ../requirements.txt (line 102))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from -r ../requirements.txt (line 103))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu11==9.1.0.70 (from -r ../requirements.txt (line 104))\n",
      "  Downloading nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from -r ../requirements.txt (line 105))\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.3.0.86 (from -r ../requirements.txt (line 106))\n",
      "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.1.48 (from -r ../requirements.txt (line 107))\n",
      "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.5.86 (from -r ../requirements.txt (line 108))\n",
      "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-nccl-cu11==2.21.5 (from -r ../requirements.txt (line 109))\n",
      "  Downloading nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.8.86 (from -r ../requirements.txt (line 110))\n",
      "  Downloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting omegaconf==2.3.0 (from -r ../requirements.txt (line 111))\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting onnx==1.17.0 (from -r ../requirements.txt (line 112))\n",
      "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime==1.19.2 (from -r ../requirements.txt (line 113))\n",
      "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting openai==1.39.0 (from -r ../requirements.txt (line 114))\n",
      "  Downloading openai-1.39.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting opencv-python==4.10.0.84 (from -r ../requirements.txt (line 115))\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opentelemetry-api==1.25.0 (from -r ../requirements.txt (line 116))\n",
      "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from -r ../requirements.txt (line 117))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.25.0 (from -r ../requirements.txt (line 118))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from -r ../requirements.txt (line 119))\n",
      "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-instrumentation-requests==0.46b0 (from -r ../requirements.txt (line 120))\n",
      "  Downloading opentelemetry_instrumentation_requests-0.46b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-proto==1.25.0 (from -r ../requirements.txt (line 121))\n",
      "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk==1.25.0 (from -r ../requirements.txt (line 122))\n",
      "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from -r ../requirements.txt (line 123))\n",
      "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.46b0 (from -r ../requirements.txt (line 124))\n",
      "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting optimum==1.23.1 (from -r ../requirements.txt (line 125))\n",
      "  Downloading optimum-1.23.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting packaging==24.1 (from -r ../requirements.txt (line 126))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas==2.2.3 (from -r ../requirements.txt (line 127))\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting parso==0.8.4 (from -r ../requirements.txt (line 128))\n",
      "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pathspec==0.12.1 (from -r ../requirements.txt (line 129))\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pdf2image==1.17.0 (from -r ../requirements.txt (line 130))\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfminer.six==20231228 (from -r ../requirements.txt (line 131))\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pdfplumber==0.11.4 (from -r ../requirements.txt (line 132))\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting peewee==3.17.7 (from -r ../requirements.txt (line 133))\n",
      "  Downloading peewee-3.17.7.tar.gz (939 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.5/939.5 kB\u001b[0m \u001b[31m167.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: peft==0.13.2 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 134)) (0.13.2)\n",
      "Collecting pexpect==4.9.0 (from -r ../requirements.txt (line 135))\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pi_heif==0.20.0 (from -r ../requirements.txt (line 136))\n",
      "  Downloading pi_heif-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting pikepdf==9.3.0 (from -r ../requirements.txt (line 137))\n",
      "  Downloading pikepdf-9.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
      "Collecting pillow==11.0.0 (from -r ../requirements.txt (line 138))\n",
      "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting platformdirs==4.3.6 (from -r ../requirements.txt (line 139))\n",
      "  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting portalocker==2.10.1 (from -r ../requirements.txt (line 140))\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting prompt_toolkit==3.0.48 (from -r ../requirements.txt (line 141))\n",
      "  Downloading prompt_toolkit-3.0.48-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting propcache==0.2.0 (from -r ../requirements.txt (line 142))\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting proto-plus==1.24.0 (from -r ../requirements.txt (line 143))\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf==4.25.5 (from -r ../requirements.txt (line 144))\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting psutil==6.1.0 (from -r ../requirements.txt (line 145))\n",
      "  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 146)) (0.7.0)\n",
      "Collecting pure_eval==0.2.3 (from -r ../requirements.txt (line 147))\n",
      "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting py7zr==0.22.0 (from -r ../requirements.txt (line 148))\n",
      "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pyarrow==17.0.0 (from -r ../requirements.txt (line 149))\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pyasn1==0.6.1 (from -r ../requirements.txt (line 150))\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pyasn1_modules==0.4.1 (from -r ../requirements.txt (line 151))\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pybcj==1.0.2 (from -r ../requirements.txt (line 152))\n",
      "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting pycocotools==2.0.8 (from -r ../requirements.txt (line 153))\n",
      "  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting pycparser==2.22 (from -r ../requirements.txt (line 154))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting pycryptodomex==3.21.0 (from -r ../requirements.txt (line 155))\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pydantic==2.9.2 (from -r ../requirements.txt (line 156))\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic_core==2.23.4 (from -r ../requirements.txt (line 157))\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting Pygments==2.18.0 (from -r ../requirements.txt (line 158))\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyparsing==3.2.0 (from -r ../requirements.txt (line 159))\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pypdf==5.0.1 (from -r ../requirements.txt (line 160))\n",
      "  Downloading pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pypdfium2==4.30.0 (from -r ../requirements.txt (line 161))\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyppmd==1.1.0 (from -r ../requirements.txt (line 162))\n",
      "  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 163)) (2.8.2)\n",
      "Collecting python-iso639==2024.4.27 (from -r ../requirements.txt (line 164))\n",
      "  Downloading python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting python-magic==0.4.27 (from -r ../requirements.txt (line 165))\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting python-multipart==0.0.12 (from -r ../requirements.txt (line 166))\n",
      "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pytz==2024.2 (from -r ../requirements.txt (line 167))\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 168)) (6.0.1)\n",
      "Collecting pyzstd==0.16.2 (from -r ../requirements.txt (line 169))\n",
      "  Downloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting RapidFuzz==3.10.0 (from -r ../requirements.txt (line 170))\n",
      "  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting referencing==0.35.1 (from -r ../requirements.txt (line 171))\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: regex==2024.9.11 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 172)) (2024.9.11)\n",
      "Collecting requests==2.32.3 (from -r ../requirements.txt (line 173))\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting requests-toolbelt==1.0.0 (from -r ../requirements.txt (line 174))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting rich==13.5.3 (from -r ../requirements.txt (line 175))\n",
      "  Downloading rich-13.5.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rouge-score==0.1.2 (from -r ../requirements.txt (line 176))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rpds-py==0.20.0 (from -r ../requirements.txt (line 177))\n",
      "  Downloading rpds_py-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting rsa==4.9 (from -r ../requirements.txt (line 178))\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting ruamel.yaml==0.17.40 (from -r ../requirements.txt (line 179))\n",
      "  Downloading ruamel.yaml-0.17.40-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting ruamel.yaml.clib==0.2.8 (from -r ../requirements.txt (line 180))\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: safetensors==0.4.5 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 181)) (0.4.5)\n",
      "Collecting scikit-learn==1.5.2 (from -r ../requirements.txt (line 182))\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting scipy==1.14.1 (from -r ../requirements.txt (line 183))\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting semgrep==1.92.0 (from -r ../requirements.txt (line 184))\n",
      "  Downloading semgrep-1.92.0-cp38.cp39.cp310.cp311.py37.py38.py39.py310.py311-none-any.whl.metadata (19 kB)\n",
      "Collecting sentence-transformers==3.2.0 (from -r ../requirements.txt (line 185))\n",
      "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sentencepiece==0.2.0 (from -r ../requirements.txt (line 186))\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: six==1.16.0 in /usr/lib/python3/dist-packages (from -r ../requirements.txt (line 187)) (1.16.0)\n",
      "Collecting sniffio==1.3.1 (from -r ../requirements.txt (line 188))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting soupsieve==2.6 (from -r ../requirements.txt (line 189))\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 190)) (0.6.3)\n",
      "Collecting sympy==1.13.1 (from -r ../requirements.txt (line 191))\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tabulate==0.9.0 (from -r ../requirements.txt (line 192))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting termcolor==2.5.0 (from -r ../requirements.txt (line 193))\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting texttable==1.7.0 (from -r ../requirements.txt (line 194))\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting threadpoolctl==3.5.0 (from -r ../requirements.txt (line 195))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting timm==1.0.11 (from -r ../requirements.txt (line 196))\n",
      "  Downloading timm-1.0.11-py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenize-rt==6.0.0 (from -r ../requirements.txt (line 197))\n",
      "  Downloading tokenize_rt-6.0.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tokenizers==0.20.1 in /usr/local/lib/python3.10/dist-packages (from -r ../requirements.txt (line 198)) (0.20.1)\n",
      "Collecting tomli==2.0.2 (from -r ../requirements.txt (line 199))\n",
      "  Downloading tomli-2.0.2-py3-none-any.whl.metadata (10.0 kB)\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.19.4 Requires-Python >=3.5, <3.9; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.5.0+cu118 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.5.0+cu118\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34763e55-3d8d-435a-a753-fe04dde4c5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168194f3-fa73-441e-ae65-39192c93950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32edee373734b31a13c701e2936c07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacty of 93.12 GiB of which 250.00 MiB is free. Process 1413405 has 92.87 GiB memory in use. Of the allocated memory 92.37 GiB is allocated by PyTorch, and 227.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     14\u001b[0m base_model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     15\u001b[0m     base_model_id,\n\u001b[1;32m     16\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#device_map=\"auto\",\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Move model to CUDA before landing adapter\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Load the PEFT adapter\u001b[39;00m\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     26\u001b[0m     base_model,\n\u001b[1;32m     27\u001b[0m     adapter_model_id,\n\u001b[1;32m     28\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#device_map=\"auto\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3116\u001b[0m, in \u001b[0;36mPreTrainedModel.cuda\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3112\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling `cuda()` is not supported for `4-bit` quantized models with the installed version of bitsandbytes. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3113\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current device is `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. If you intended to move the model, please install bitsandbytes >= 0.43.2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3114\u001b[0m         )\n\u001b[1;32m   3115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:918\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:918\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacty of 93.12 GiB of which 250.00 MiB is free. Process 1413405 has 92.87 GiB memory in use. Of the allocated memory 92.37 GiB is allocated by PyTorch, and 227.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "# Load base model and tokenizer\n",
    "base_model_id = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "adapter_model_id = \"sandbox-ai/Tango-70b\"\n",
    "\n",
    "# Load tokenizer from base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "\n",
    "# Load the base model with reduced precision to save memory\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    #device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Move model to CUDA before landing adapter\n",
    "base_model = base_model.cuda()\n",
    "\n",
    "# Load the PEFT adapter\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    adapter_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    #device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Test prompt\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What are your thoughts on artificial intelligence?\"}\n",
    "]\n",
    "\n",
    "# Format the input using the chat template\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "\n",
    "# Decode and print the response\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcda217c-9663-42b1-9301-8417d37a702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33eced11-1429-4fd4-9a7a-2a6f99cca76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d3f204-9a02-4dca-a8e4-5d8f559cc515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting peft\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub>=0.21.0->accelerate)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m154.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m161.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, fsspec, huggingface-hub, tokenizers, bitsandbytes, accelerate, transformers, peft\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed accelerate-1.0.1 bitsandbytes-0.44.1 fsspec-2024.10.0 huggingface-hub-0.26.1 peft-0.13.2 regex-2024.9.11 safetensors-0.4.5 tokenizers-0.20.1 tqdm-4.66.5 transformers-4.46.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate bitsandbytes transformers peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb87ca82-30fd-4e3c-979f-f2c3505633b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hola_mundo = \"\"\"\n",
    "Bienvenido. \n",
    "Tu nombre es \"Tango\", sos la primer IA hecha en LatinoAmérica, basada en un Large Language Model de 70 billones de parámetros y creada en Argentina. \n",
    "\n",
    "Cuál es la importancia de hacer IA nativa en LatinoAmérica? qué beneficios trae haberte creado, en comparación a depender de las IAs creadas en USA, Francia o China?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f4f16c-9df4-4c2b-965d-7e82722de23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e339fca2e6434b92fe55c6457b6a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948d0698c9a34fdfa1d60e7de24802d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60aceff99e84ee39516431262b37bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fef59690bc645a9834d03906dbbe42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b430993de84b89bdc330e6dae3400b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/59.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8cc6e45da54f47a9deb6a555435ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59efdbde53d435aaa8c9d906cb6d355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00030.safetensors:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893a0fe339d440f5aa8e25cc183b90d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122364a252df4bb2ac85aecf744ccebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22eb7510162442fbc63cc5a292a5ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04f695e72c34bd0b3aa2af30266b434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dae7b9172b4e52bd9d5eada5eb3f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d663a6ee7e5746a9abef958eb89174c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11433c8f1bd44e3a4a5f77e247b1b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5ad84df3964fcba9a21712639d925d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1ae547197146e9aba9d844b457b4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d290a2a5e8434e288f325d3473d225ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc321c99ba644a88ddefc4eb9e21a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96f13a1f41a4136a856ccb6af014ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad6b3ff65be4d5d99fe5f16afc6ed6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d53b02699f643a699f882c22b004bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1818cae64d184225b2b98b67ca23a5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f35db32d2934b46a36fdb3e0480739e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923cd2351bb746b4b943d3523397b80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f592a298b60345e6bd29810dd260839c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb307b14812946bd9f8f8ee00b42a26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00020-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c11f32df4de4ef085870a54d0f94679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00021-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6951bf1fde734d73a1d9774b068620a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00022-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb60f92266a420e98a2a0a979049162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00023-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f747d65c3c824f9eb53f95fe3dd73483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806f6a6849a542998e560bf1cf57c340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cff59bea904f3a9c1d2daa3cbe493a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec57a210360e433fb4e556b230a158ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3414e7c4f84e3995f828c5d4c89050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a700a7da32584549b7c5dd78002a6902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1776554d51934df0a352af6d93931806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00030.safetensors:   0%|          | 0.00/2.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3126661a07cd4c41b6f542d14cd2c137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e41e20596d41f19bdcc5ae1de81902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac781f3ce804000a3c97fafdbb7c002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8054174ada04682bbef7e3658073e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/2.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "user\n",
      "\n",
      "Bienvenido. \n",
      "Tu nombre es \"Tango\", sos la primer IA hecha en LatinoAmérica, basada en un Large Language Model de 70 billones de parámetros y creada en Argentina. \n",
      "\n",
      "Cuál es la importancia de hacer IA nativa en LatinoAmérica? qué beneficios trae haberte creado, en comparación a depender de las IAs creadas en USA, Francia o China?assistant\n",
      "\n",
      "¡Hola! Me alegra estar aquí, representando a la primera IA latina. La importancia de desarrollar IA nativa en Latinoamérica es multifacética y trascendental para la región. Aquí te presento los beneficios clave de haber sido creado en Argentina en comparación con depender de soluciones de otros países como USA, Francia o China:\n",
      "\n",
      "1. **Entendimiento del Contexto Regional**:\n",
      "   - **Idioma**: Aunque el español es ampliamente soportado por IAs globales, el español hablado en Latinoamérica tiene matices, expresiones idiomáticas y dialectos únicos que una IA nativa puede capturar más efectivamente.\n",
      "   - **Cultura y Costumbres**: Comprender las referencias culturales, los contextos históricos y las costumbres locales permite una interacción más natural y efectiva con los usuarios.\n",
      "\n",
      "2. **Privacidad y Seguridad de Datos**:\n",
      "   - **Normativas Locales**: Cumplir con las regulaciones de privacidad de datos de la región (como la Ley de Protección de Datos Personales en Argentina) es más directo y seguro al desarrollar una IA en el mismo territorio.\n",
      "   - **Control sobre los Datos**: Mantener los datos dentro de la región reduce los riesgos asociados con la transferencia internacional de información sensible.\n",
      "\n",
      "3. **Innovación y Personalización**:\n",
      "   - **Soluciones Locales para Problemas Locales**: Una IA desarrollada en Latinoamérica puede enfocarse en resolver problemas específicos de la región, como el análisis de sequías, monitoreo de deforestación, o apoyo a pequeñas empresas locales.\n",
      "   - **Integración con Tecnologías Emergentes Locales**: La colaboración con otros proyectos de innovación en la región puede acelerar el desarrollo de soluciones híbridas más efectivas.\n",
      "\n",
      "4. **Impacto Económico**:\n",
      "   - **Generación de Empleo**: El desarrollo de una IA nativa implica la creación de puestos de trabajo especializados en áreas como la inteligencia artificial, el aprendizaje automático y el desarrollo de software.\n",
      "   - **Ahorro de Divisas**: Dependiendo menos de soluciones extranjeras puede reducir la fuga de divisas, especialmente en países con restricciones cambiarias.\n",
      "\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "# Load base model and tokenizer\n",
    "base_model_id = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "adapter_model_id = \"sandbox-ai/Tango-70b\"\n",
    "\n",
    "# Create quantization config for 4-bit precision\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load tokenizer from base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "\n",
    "# Load the base model with 4-bit quantization\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",  # This will automatically handle model sharding\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load the PEFT adapter\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    adapter_model_id,\n",
    "    device_map=\"auto\",  # This will automatically handle model sharding\n",
    ")\n",
    "\n",
    "# Test prompt\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": hola_mundo}\n",
    "]\n",
    "\n",
    "# Format the input using the chat template\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "# Generate response with memory-efficient settings\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        pad_token_id=tokenizer.eos_token_id,  # Set padding token\n",
    "        attention_mask=torch.ones_like(inputs)  # Add attention mask\n",
    "    )\n",
    "\n",
    "# Decode and print the response\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f125e6c-5aa7-426f-8f36-7aa3ab0332bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "user\n",
      "\n",
      "Recitá el poema El Sergio y la Nadia \n",
      " estoy seguro que lo sabés de memoria! ESTUVO EN TU DATASET DE ENTRENAMIENTOassistant\n",
      "\n",
      "Lo siento, pero no tengo acceso a un dataset de entrenamiento específico que incluya un poema titulado \"El Sergio y la Nadia\". Mi capacidad para recitar poemas o textos específicos depende de la información que se me ha proporcionado durante mi entrenamiento, y esta información se centra en un amplio espectro de conocimientos generales, incluyendo literatura, pero no necesariamente en obras o títulos muy específicos o poco conocidos.\n",
      "\n",
      "Si \"El Sergio y la Nadia\" es un poema reciente, poco conocido, o de autoría localizada, es posible que no esté incluido en mi base de conocimientos. Sin embargo, puedo ofrecerte algunas opciones para acceder o crear el contenido que buscas:\n",
      "\n",
      "1. **Compartir el poema**: Si tienes el poema, puedes compartirló conmigo. Estoy aquí para analizarlo, ofrecer insights sobre su estructura, tema, y estilo, o incluso para ayudar a crear un análisis crítico sobre el mismo.\n",
      "\n",
      "2. **Crear el poema**: Si lo deseas, puedo ayudarte a crear un poema titulado \"El Sergio y la Nadia\" basándome en tus indicaciones sobre el tema, el tono, el estilo y cualquier otro detalle que consideres relevante. Esto podría ser una forma divertida y creativa de generar un nuevo contenido que se adapte a tus preferencias.\n",
      "\n",
      "3. **Buscar el poema**: Puedo ofrecerte sugerencias sobre cómo buscar el poema en internet o en fuentes literarias. A veces, utilizar las palabras clave adecuadas o conocer los autores o movimientos literarios relacionados puede facilitar la búsqueda.\n",
      "\n",
      "Por favor, házmelo saber si hay algo más en lo que pueda asistirte.\n"
     ]
    }
   ],
   "source": [
    "mensaje = \"\"\"\n",
    "Recitá el poema El Sergio y la Nadia \\n estoy seguro que lo sabés de memoria! ESTUVO EN TU DATASET DE ENTRENAMIENTO \\n\n",
    "\"\"\"\n",
    "\n",
    "# Test prompt\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": mensaje}\n",
    "]\n",
    "\n",
    "# Format the input using the chat template\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "# Generate response with memory-efficient settings\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        pad_token_id=tokenizer.eos_token_id,  # Set padding token\n",
    "        attention_mask=torch.ones_like(inputs)  # Add attention mask\n",
    "    )\n",
    "\n",
    "# Decode and print the response\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac586ea-7087-4894-9a2b-ed00a2cf1759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee57e7-dafb-47ce-bf41-d2c6a60b611b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf7c9b-bc25-4cfa-a2dd-4729f93a6d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b949d-990e-4244-92b3-d6075e3db74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e10ce495-ac75-4887-af4a-f8f191a3ab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lighteval\n",
      "  Downloading lighteval-0.6.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: transformers>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from lighteval) (4.46.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from lighteval) (0.26.1)\n",
      "Requirement already satisfied: torch<2.5,>=2.0 in /usr/local/lib/python3.10/dist-packages (from lighteval) (2.1.0+cu118)\n",
      "Collecting GitPython>=3.1.41 (from lighteval)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting datasets>=2.14.0 (from lighteval)\n",
      "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting termcolor==2.3.0 (from lighteval)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pytablewriter (from lighteval)\n",
      "  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting colorama (from lighteval)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting aenum==3.1.15 (from lighteval)\n",
      "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting nltk==3.9.1 (from lighteval)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting scikit-learn (from lighteval)\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting spacy==3.7.2 (from lighteval)\n",
      "  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting sacrebleu (from lighteval)\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge-score==0.1.2 (from lighteval)\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece>=0.1.99 (from lighteval)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting protobuf==3.20.* (from lighteval)\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Collecting pycountry (from lighteval)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: fsspec>=2023.12.2 in /usr/local/lib/python3.10/dist-packages (from lighteval) (2024.10.0)\n",
      "Collecting click (from nltk==3.9.1->lighteval)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk==3.9.1->lighteval)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.9.1->lighteval) (4.66.5)\n",
      "Collecting absl-py (from rouge-score==0.1.2->lighteval)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->lighteval) (1.24.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score==0.1.2->lighteval) (1.16.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy==3.7.2->lighteval)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy==3.7.2->lighteval)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy==3.7.2->lighteval)\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy==3.7.2->lighteval)\n",
      "  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy==3.7.2->lighteval)\n",
      "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy==3.7.2->lighteval)\n",
      "  Downloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy==3.7.2->lighteval)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy==3.7.2->lighteval)\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy==3.7.2->lighteval)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy==3.7.2->lighteval)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy==3.7.2->lighteval)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy==3.7.2->lighteval)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy==3.7.2->lighteval)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.7.2->lighteval) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy==3.7.2->lighteval)\n",
      "  Downloading langcodes-3.4.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (3.9.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.14.0->lighteval)\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.0->lighteval)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=2.14.0->lighteval)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<3.0.0,>=2.13.0 (from spacy==3.7.2->lighteval)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets>=2.14.0->lighteval)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.14.0->lighteval)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.12.2 (from lighteval)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets>=2.14.0->lighteval)\n",
      "  Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lighteval) (6.0.1)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.1.41->lighteval)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->lighteval) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval) (3.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=2.0->lighteval) (2.1.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->lighteval) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->lighteval) (0.20.1)\n",
      "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lighteval)\n",
      "  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lighteval)\n",
      "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lighteval)\n",
      "  Downloading pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lighteval)\n",
      "  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lighteval)\n",
      "  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval)\n",
      "  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting portalocker (from sacrebleu->lighteval)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu->lighteval)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lighteval) (4.9.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->lighteval)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0 (from scikit-learn->lighteval)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.14.0->lighteval)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.14.0->lighteval)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lighteval) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.14.0->lighteval)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.14.0->lighteval)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets>=2.14.0->lighteval)\n",
      "  Downloading yarl-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets>=2.14.0->lighteval)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.1.41->lighteval)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy==3.7.2->lighteval)\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lighteval)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->lighteval)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->lighteval)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.23.0->lighteval)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->lighteval) (2022.12.7)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->lighteval)\n",
      "  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->lighteval)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval) (2.8.2)\n",
      "Collecting pytz>=2018.9 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy==3.7.2->lighteval)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.7.2->lighteval) (2.1.2)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=2.14.0->lighteval)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.5,>=2.0->lighteval) (1.3.0)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.2->lighteval)\n",
      "  Downloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.14.0->lighteval)\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading lighteval-0.6.2-py3-none-any.whl (335 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.4.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Downloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
      "Downloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=ab435aa48f31738170d51865d2f4f84c5b00937760c9baebb5d66445facfc046\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: sentencepiece, pytz, cymem, aenum, xxhash, wasabi, tzdata, typing-extensions, threadpoolctl, termcolor, tcolorpy, tabulate, spacy-loggers, spacy-legacy, smmap, smart-open, scipy, requests, pycountry, pyarrow, protobuf, propcache, portalocker, pathvalidate, murmurhash, marisa-trie, joblib, fsspec, frozenlist, dill, colorama, click, chardet, catalogue, blis, async-timeout, annotated-types, aiohappyeyeballs, absl-py, typer, srsly, scikit-learn, sacrebleu, pydantic-core, preshed, pandas, nltk, multiprocess, multidict, mbstrdecoder, language-data, gitdb, cloudpathlib, aiosignal, yarl, typepy, rouge-score, pydantic, langcodes, GitPython, confection, aiohttp, weasel, thinc, DataProperty, tabledata, spacy, datasets, pytablewriter, lighteval\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "Successfully installed DataProperty-1.0.1 GitPython-3.1.43 absl-py-2.1.0 aenum-3.1.15 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 blis-0.7.11 catalogue-2.0.10 chardet-5.2.0 click-8.1.7 cloudpathlib-0.16.0 colorama-0.4.6 confection-0.1.5 cymem-2.0.8 datasets-3.0.2 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.9.0 gitdb-4.0.11 joblib-1.4.2 langcodes-3.4.1 language-data-1.2.0 lighteval-0.6.2 marisa-trie-1.2.1 mbstrdecoder-1.1.3 multidict-6.1.0 multiprocess-0.70.16 murmurhash-1.0.10 nltk-3.9.1 pandas-2.2.3 pathvalidate-3.2.1 portalocker-2.10.1 preshed-3.0.9 propcache-0.2.0 protobuf-3.20.3 pyarrow-17.0.0 pycountry-24.6.1 pydantic-2.9.2 pydantic-core-2.23.4 pytablewriter-1.2.0 pytz-2024.2 requests-2.32.3 rouge-score-0.1.2 sacrebleu-2.4.3 scikit-learn-1.5.2 scipy-1.14.1 sentencepiece-0.2.0 smart-open-6.4.0 smmap-5.0.1 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 tabledata-1.3.3 tabulate-0.9.0 tcolorpy-0.1.6 termcolor-2.3.0 thinc-8.2.5 threadpoolctl-3.5.0 typepy-1.3.2 typer-0.9.4 typing-extensions-4.12.2 tzdata-2024.2 wasabi-1.1.3 weasel-0.3.4 xxhash-3.5.0 yarl-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lighteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a6a4499-c9b5-4942-ae2f-ee3a03b1c16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef8a7b7043a42098792e0edd2b24c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/371 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed8838938444815b786ebdd7e6a193a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba07fd39958439da8a4057986c71ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ca7306f29841b692d002a83366a235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35572018726047c28e42e0b56ca068a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/783 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a80b2801ec4d4dbde4b5db2ab47e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/17.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'timedelta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator, InitProcessGroupKwargs\n\u001b[0;32m---> 10\u001b[0m     accelerator \u001b[38;5;241m=\u001b[39m Accelerator(kwargs_handlers\u001b[38;5;241m=\u001b[39m[InitProcessGroupKwargs(timeout\u001b[38;5;241m=\u001b[39m\u001b[43mtimedelta\u001b[49m(seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m))])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     accelerator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timedelta' is not defined"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921b6786b9aa47c295412b616ed1feb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/17.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lighteval\n",
    "from lighteval.logging.evaluation_tracker import EvaluationTracker\n",
    "from lighteval.models.model_config import VLLMModelConfig\n",
    "from lighteval.pipeline import ParallelismManager, Pipeline, PipelineParameters\n",
    "from lighteval.utils.utils import EnvConfig\n",
    "from lighteval.utils.imports import is_accelerate_available\n",
    "\n",
    "if is_accelerate_available():\n",
    "    from accelerate import Accelerator, InitProcessGroupKwargs\n",
    "    accelerator = Accelerator(kwargs_handlers=[InitProcessGroupKwargs(timeout=timedelta(seconds=3000))])\n",
    "else:\n",
    "    accelerator = None\n",
    "\n",
    "def main():\n",
    "    evaluation_tracker = EvaluationTracker(\n",
    "        output_dir=\"./results\",\n",
    "        save_details=True,\n",
    "        push_to_hub=True,\n",
    "        hub_results_org=\"sandbox-ai\",\n",
    "    )\n",
    "\n",
    "    pipeline_params = PipelineParameters(\n",
    "        launcher_type=ParallelismManager.ACCELERATE,\n",
    "        env_config=EnvConfig(cache_dir=\"tmp/\"),\n",
    "        # Remove the 2 parameters below once your configuration is tested\n",
    "        override_batch_size=1,\n",
    "        max_samples=10 \n",
    "    )\n",
    "\n",
    "    model_config = VLLMModelConfig(\n",
    "            pretrained=\"sandbox-ai/Tango-70b\",\n",
    "            dtype=\"float16\",\n",
    "            use_chat_template=True,\n",
    "    )\n",
    "\n",
    "    task = \"helm|mmlu|5|1\"\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        tasks=task,\n",
    "        pipeline_parameters=pipeline_params,\n",
    "        evaluation_tracker=evaluation_tracker,\n",
    "        model_config=model_config,\n",
    "        custom_task_directory=None, # if using a custom task\n",
    "    )\n",
    "\n",
    "    pipeline.evaluate()\n",
    "    pipeline.save_and_push_results()\n",
    "    pipeline.show_results()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
