# tango


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Prerequisites

- Python 3.10 or later
- CUDA-compatible GPU (CUDA 11.8 recommended)
- Git

## Installation

1.  Clone the repository:

    ``` bash
    git clone https://github.com/your-username/your-repo-name.git
    cd your-repo-name
    ```

2.  Create and activate a virtual environment (optional but
    recommended):

    ``` bash
    python3 -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  Install PyTorch with CUDA support:

    ``` bash
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    ```

4.  Install the required packages:

    ``` bash
    pip install -r requirements.txt
    ```

5.  Install HQQ:

    ``` bash
    git clone https://github.com/mobiusml/hqq.git
    cd hqq
    pip install .
    cd hqq/kernels
    python setup_cuda.py install
    cd ../..
    ```

## Usage

To run the training script, use the following command:

``` bash
python train.py [arguments]
```

### Important Arguments

- `--world_size`: Number of GPUs to use. -1 = all available GPUs.
- `--train_type`: Training type (e.g., “qlora”, “full”, “lora”,
  “custom_qlora”)
- `--batch_size`: Batch size per GPU
- `--num_epochs`: Number of training epochs
- `--dataset`: Dataset to use (e.g., “alpaca”, “alpaca_sample”, “dummy”)
- `--model_name`: Model to train (e.g., “meta-llama/Llama-2-7b-hf”)
- `--precision`: Training precision (e.g., “bf16”, “fp32”)

For a full list of arguments and their descriptions, run:

``` bash
python train.py --help
```

### Quick run

``` bash
python train.py \
--model_name meta-llama/Llama-2-70b-hf \
--batch_size 2 \
--context_length 512 \
--precision bf16 \
--train_type qlora \
--use_gradient_checkpointing true \
--use_cpu_offload true \
--dataset alpaca \
--reentrant_checkpointing true
```

this uses over 130gb of cpu ram, but note you can use swap memory. note
that if you don’t use cpu offloading (`use_cpu_offload false`), ram
usage will be much lower.

## Running Jupyter Notebook

To run Jupyter Notebook for interactive development:

1.  Start Jupyter Notebook:

    ``` bash
    jupyter notebook
    ```

2.  Open your browser and go to `http://localhost:8888`

## Notes

- Make sure your CUDA version is compatible with your GPU. You can check
  supported architectures and adjust the `TORCH_CUDA_ARCH_LIST`
  environment variable if needed.
- The project uses specific versions of transformers library, excluding
  versions 4.38.\* and 4.39.\*. If you encounter issues, you may need to
  adjust the version constraints.
- For optimal performance, ensure you have the latest NVIDIA drivers
  installed for your GPU.

## Troubleshooting

If you encounter any issues with CUDA or GPU support, make sure: 1. Your
NVIDIA drivers are up to date 2. The installed PyTorch version matches
your CUDA version 3. Your GPU is CUDA-compatible and supported by the
installed PyTorch version

## Contributing

ask the pibes

## Developer Guide

If you are new to using `nbdev` here are some useful pointers to get you
started.

### Install tango in Development mode

``` sh
# make sure tango package is installed in development mode
$ pip install -e .

# make changes under nbs/ directory
# ...

# compile to have changes apply to tango
$ nbdev_prepare
```

## Package
